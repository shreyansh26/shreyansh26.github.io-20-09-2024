<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Shreyansh Singh</title>
    <link>https://shreyansh26.github.io/project/</link>
      <atom:link href="https://shreyansh26.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© Shreyansh Singh 2024</copyright><lastBuildDate>Mon, 19 Jun 2023 20:10:00 +0530</lastBuildDate>
    <image>
      <url>https://shreyansh26.github.io/img/Shreyansh.jpg</url>
      <title>Projects</title>
      <link>https://shreyansh26.github.io/project/</link>
    </image>
    
    <item>
      <title>Flash Attention in Pytorch</title>
      <link>https://shreyansh26.github.io/project/flash-attention-pytorch/</link>
      <pubDate>Mon, 19 Jun 2023 20:10:00 +0530</pubDate>
      <guid>https://shreyansh26.github.io/project/flash-attention-pytorch/</guid>
      <description>&lt;p&gt;A simplified implementation of FlashAttention in PyTorch. I have implemented the forward pass and backward pass algorithms from the paper, and also shown that it is equivalent to the normal attention formulation in Transformers. I also include some code for benchmarking.&lt;/p&gt;
&lt;p&gt;Note that this is for educational purposes only as I haven&amp;rsquo;t implemented any of the CUDA and SRAM memory tricks as described in the paper.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>KV Cache in Nanogpt</title>
      <link>https://shreyansh26.github.io/project/kv-cache-nanogpt/</link>
      <pubDate>Sat, 17 Jun 2023 20:18:33 +0530</pubDate>
      <guid>https://shreyansh26.github.io/project/kv-cache-nanogpt/</guid>
      <description>&lt;p&gt;A modification of nanoGPT to use KV-Cache during inference. Using a KV Cache helps speed up inference since we don&amp;rsquo;t have to do attention re-computation over the entire generated sequence every time to generate the next tokens.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ConvNeXt - Adversarial images generation</title>
      <link>https://shreyansh26.github.io/project/convnext-adversarial/</link>
      <pubDate>Sun, 06 Mar 2022 20:40:05 +0530</pubDate>
      <guid>https://shreyansh26.github.io/project/convnext-adversarial/</guid>
      <description>&lt;p&gt;I implemented &lt;a href=&#34;https://twitter.com/stanislavfort/status/1481263565998805002?s=20&#34;&gt;Stanislav Fort&amp;rsquo;s project&lt;/a&gt; in Pytorch. The Github repo has a notebook which looks at generating adversarial images to &amp;ldquo;fool&amp;rdquo; the ConvNeXt model&amp;rsquo;s image classification capabilities. ConvNeXt came out earlier this year (2022) from Meta AI.&lt;/p&gt;
&lt;p&gt;The FGSM (Fast Gradient Sign Method) is a great algorithm to attack models in a white-box fashion with the goal of misclassification. Noise is added to the input image (not randomly) but in a manner such that the direction is the same as the gradient of the cost function with respect to the data.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ML Optimizers in JAX</title>
      <link>https://shreyansh26.github.io/project/jax-optimizers/</link>
      <pubDate>Sun, 26 Sep 2021 19:19:28 +0530</pubDate>
      <guid>https://shreyansh26.github.io/project/jax-optimizers/</guid>
      <description>&lt;p&gt;Implementations of some popular optimizers from scratch for a simple model i.e., Linear Regression on a dataset of 5 features. The goal of this project was to understand how these optimizers work under the hood and try to do a toy implementation myself. I also use a bit of JAX magic to perform the differentiation of the loss function w.r.t to the weights and the bias without explicitly writing their derivatives as a separate function. This can help to generalize this notebook for other types of loss functions as well.&lt;/p&gt;
&lt;p&gt;The optimizers I have implemented are -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Batch Gradient Descent&lt;/li&gt;
&lt;li&gt;Batch Gradient Descent + Momentum&lt;/li&gt;
&lt;li&gt;Nesterov Accelerated Momentum&lt;/li&gt;
&lt;li&gt;Adagrad&lt;/li&gt;
&lt;li&gt;RMSprop&lt;/li&gt;
&lt;li&gt;Adam&lt;/li&gt;
&lt;li&gt;Adamax&lt;/li&gt;
&lt;li&gt;Nadam&lt;/li&gt;
&lt;li&gt;Adabelief&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Privacy-preserving Deep Learning for Medical Image Classification</title>
      <link>https://shreyansh26.github.io/project/privacy-ml/</link>
      <pubDate>Mon, 25 Nov 2019 17:53:33 +0530</pubDate>
      <guid>https://shreyansh26.github.io/project/privacy-ml/</guid>
      <description>&lt;p&gt;Privacy Preserving Deep Learning for Medical Image Classification to detect chest pneumonia in chest X-ray images.&lt;/p&gt;
&lt;p&gt;Uses TF-Encrypted to implement Secure Multiparty Computation (SMPC) and Differential Privacy. SMPC helps to provide secure predictions and Differential Privacy is used to enhance privacy.&lt;/p&gt;
&lt;p&gt;The base model is a VGG16 model which is made secure and privacy-preserving.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Network Intrusion Detection in an Adversarial setting</title>
      <link>https://shreyansh26.github.io/project/nids/</link>
      <pubDate>Sun, 05 May 2019 17:28:30 +0530</pubDate>
      <guid>https://shreyansh26.github.io/project/nids/</guid>
      <description>&lt;p&gt;A study on fooling Machine Learning/Deep Learning based Network Intrusion Detection systems to prevent them from detecting intrusions. We implement various adversarial machine learning attacks on network traffic data and analyze their effect on the accuracy of the model in detecting intrusions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linux Malware detection using Machine Learning</title>
      <link>https://shreyansh26.github.io/project/linux-malware/</link>
      <pubDate>Thu, 03 Jan 2019 18:07:13 +0530</pubDate>
      <guid>https://shreyansh26.github.io/project/linux-malware/</guid>
      <description>&lt;p&gt;Implemented various papers on Linux Malware detection, where I analysed the structure of ELF files to determine whether they were malicious or benign. Approaches included the analysis of -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Symbol Table&lt;/li&gt;
&lt;li&gt;Opcode frequency&lt;/li&gt;
&lt;li&gt;ELF file metadata&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Multilingual Surface Realization for NLG</title>
      <link>https://shreyansh26.github.io/project/msr-nlg/</link>
      <pubDate>Mon, 23 Jul 2018 16:52:28 +0530</pubDate>
      <guid>https://shreyansh26.github.io/project/msr-nlg/</guid>
      <description>&lt;p&gt;A shared task organized at ACL 2018 (Association for Computational Linguistics, Melbourne, Australia). The task aims to determining the word order and inflecting words from given unordered Universal Dependencies (UD) structures from which word order information has been removed and the tokens have been lemmatized.
Worked on techniques like Language Modelling and Neural Machine Translation methods to solve the problem of reinflection and correct word order generation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Review Opinion Diversificatio&amp;shy;n</title>
      <link>https://shreyansh26.github.io/project/revopid/</link>
      <pubDate>Mon, 20 Nov 2017 17:15:45 +0530</pubDate>
      <guid>https://shreyansh26.github.io/project/revopid/</guid>
      <description>&lt;p&gt;Work done as a part of the organizing team of RevOpiD, a shared task organized at IJCNLP 2017 (International Joint Conference on Natural Language Processing, Taipei, Taiwan).
The task aims to produce a top-k ranking of product reviews which can sufficiently represent the gist of opinions expressed in all the reviews of that product.
Implemented the official baseline for Subtask-B of the shared task. Also volunteered to annotate gold dataset for the shared task.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Worldlink - Social Networking Website</title>
      <link>https://shreyansh26.github.io/project/worldlink/</link>
      <pubDate>Fri, 20 Oct 2017 18:14:20 +0530</pubDate>
      <guid>https://shreyansh26.github.io/project/worldlink/</guid>
      <description>&lt;p&gt;Created a social networking website (webapp) using the Django framework as a part of my curriculum
project.&lt;/p&gt;
&lt;p&gt;Implemented features like user authentication, profile creation and edit options, posts/blogs creation,
like and comment on the posts, searching other users, personal messaging between users, following other
users and a meme generator for generating memes.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
