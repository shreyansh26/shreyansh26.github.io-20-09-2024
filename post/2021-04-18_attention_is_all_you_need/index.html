<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.6.2">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Shreyansh Singh">

  
  
  
    
  
  <meta name="description" content="Paper: Attention Is All You Need
Link: https://bit.ly/3aklLFY
Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin
Code: https://github.com/tensorflow/tensor2tensor
 What? Proposes Transformers, a new simple architecture for sequence transduction that uses only an attention mechanism and does not use any kind of recurrence or convolution. This model achieves SOTA (at the time) on the WMT 2014 English-to-French translation task with a score of 41.">

  
  <link rel="alternate" hreflang="en-us" href="https://shreyansh26.github.io/post/2021-04-18_attention_is_all_you_need/">

  


  
  
  
  <meta name="theme-color" content="#3f51b5">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css" crossorigin="anonymous" title="hl-light">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css" crossorigin="anonymous" title="hl-dark" disabled>
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=B612+Mono:400,700%7COrbitron:400,700%7CSpace+Mono:400,700%7CLato%7CMontserrat%7CInconsolata%7CAnonymous+Pro&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  





<script async src="https://www.googletagmanager.com/gtag/js?id=UA-153509490-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           document.location = url;
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target);  
  }

  gtag('js', new Date());
  gtag('config', 'UA-153509490-1', {});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/shreyansh-icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/shreyansh-icon-192.png">

  <link rel="canonical" href="https://shreyansh26.github.io/post/2021-04-18_attention_is_all_you_need/">

  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  <meta property="twitter:image" content="https://shreyansh26.github.io/post/2021-04-18_attention_is_all_you_need/featured.png">
  
  <meta property="twitter:site" content="@shreyansh_26">
  <meta property="twitter:creator" content="@shreyansh_26">
  
  <meta property="og:site_name" content="Shreyansh Singh">
  <meta property="og:url" content="https://shreyansh26.github.io/post/2021-04-18_attention_is_all_you_need/">
  <meta property="og:title" content="Paper Notes #1 - Attention Is All You Need | Shreyansh Singh">
  <meta property="og:description" content="Paper: Attention Is All You Need
Link: https://bit.ly/3aklLFY
Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin
Code: https://github.com/tensorflow/tensor2tensor
 What? Proposes Transformers, a new simple architecture for sequence transduction that uses only an attention mechanism and does not use any kind of recurrence or convolution. This model achieves SOTA (at the time) on the WMT 2014 English-to-French translation task with a score of 41."><meta property="og:image" content="https://shreyansh26.github.io/post/2021-04-18_attention_is_all_you_need/featured.png">
  <meta property="twitter:image" content="https://shreyansh26.github.io/post/2021-04-18_attention_is_all_you_need/featured.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2021-04-18T16:57:49&#43;05:30">
    
    <meta property="article:modified_time" content="2021-04-18T16:57:49&#43;05:30">
  

  


    






  






<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://shreyansh26.github.io/post/2021-04-18_attention_is_all_you_need/"
  },
  "headline": "Paper Notes #1 - Attention Is All You Need",
  
  "image": [
    "https://shreyansh26.github.io/post/2021-04-18_attention_is_all_you_need/featured.png"
  ],
  
  "datePublished": "2021-04-18T16:57:49+05:30",
  "dateModified": "2021-04-18T16:57:49+05:30",
  
  "author": {
    "@type": "Person",
    "name": "Shreyansh Singh"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Shreyansh Singh",
    "logo": {
      "@type": "ImageObject",
      "url": "https://shreyansh26.github.io/img/shreyansh-icon-512.png"
    }
  },
  "description": "Paper: Attention Is All You Need\nLink: https://bit.ly/3aklLFY\nAuthors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\nCode: https://github.com/tensorflow/tensor2tensor\n What? Proposes Transformers, a new simple architecture for sequence transduction that uses only an attention mechanism and does not use any kind of recurrence or convolution. This model achieves SOTA (at the time) on the WMT 2014 English-to-French translation task with a score of 41."
}
</script>

  

  


  


  

<style>

    @font-face {
        font-family: monaco123;
        font-weight: 100%;
        font-style: normal;
        src: url("/fonts/MONACO.TTF");
    } 

    code {
        font-family: monaco123;
        font-size: 100%;
    }

</style>

<script data-ad-client="ca-pub-8708413956078710" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>




  <title>Paper Notes #1 - Attention Is All You Need | Shreyansh Singh</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    
    
      <a class="navbar-brand" href="/">Shreyansh Singh</a>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/post/"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/files/Shreyansh_Resume.pdf"><span>CV</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item">
        <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
      </li>
      

      

    </ul>

  </div>
</nav>


  <article class="article">

  




















  
  
    
  


<div class="article-container pt-3">
  <h1>Paper Notes #1 - Attention Is All You Need</h1>

  
  <p class="page-subtitle">The first of the paper notes series. This is where I briefly summarise the important papers that I read for my job or just for fun :P</p>
  

  


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/shreyansh-singh/">Shreyansh Singh</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Apr 18, 2021
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    5 min read
  </span>
  

  
  
  
  <span class="middot-divider"></span>
  <a href="/post/2021-04-18_attention_is_all_you_need/#disqus_thread"></a>
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/categories/machine-learning/">Machine Learning</a></span>
  

</div>

  













<div class="btn-links mb-3">
  
  








  









  
    
  











</div>


</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 435px;">
  <div style="position: relative">
    <img src="/post/2021-04-18_attention_is_all_you_need/featured_hu7e4749af920effda3d8f1f91cdf12223_59257_720x0_resize_lanczos_2.png" alt="" class="featured-image">
    <span class="article-header-caption">Attention Is All You Need</span>
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      <p><strong>Paper</strong>: Attention Is All You Need<br>
<strong>Link</strong>: <a href="https://bit.ly/3aklLFY">https://bit.ly/3aklLFY</a><br>
<strong>Authors</strong>: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin<br>
<strong>Code</strong>: <a href="https://github.com/tensorflow/tensor2tensor">https://github.com/tensorflow/tensor2tensor</a></p>
<hr>
<h2 id="what">What?</h2>
<p>Proposes Transformers, a new simple architecture for sequence transduction that uses only an attention mechanism and does not use any kind of recurrence or convolution. This model achieves SOTA (at the time) on the WMT 2014 English-to-French translation task with a score of 41.0 BLEU. Also beats the existing best results on the WMT 2014 English-to-German translation task with a score of 28.4 BLEU. The training cost is also much less than the best models chosen in the paper (at the time).</p>
<h2 id="why">Why?</h2>
<p>Existing recurrent models like RNNs, LSTMs or GRUs work sequentially. They align the positions to steps in computation time. They generate a sequence of hidden states as a function of the previous hidden state and the input for the current position. But sequential computation has constraints. They are not easily parallelizable which is required when the sequence lengths become large. The Transformer model eschews recurrence and allows for more parallelization and requires less training time to achieve SOTA in the machine translation task.</p>
<h2 id="how">How?</h2>













<figure>


  <a data-fancybox="" href="/post/2021-04-18_attention_is_all_you_need/images/arch.PNG" data-caption="Detailed Transformer Architecture">
<img src="/post/2021-04-18_attention_is_all_you_need/images/arch.PNG" alt="" ></a>


  
  
  <figcaption>
    Detailed Transformer Architecture
  </figcaption>


</figure>

<p>The model is auto-regressive, it consumes the previously generated symbols as additional input when generating the next.</p>
<h3 id="encoder">Encoder</h3>
<p>The figure above shows just one layer of the encoder on the left. There are <code>N=6</code> such layers. Each layer has two sub-layers - a multi-head self-attention layer and a position-wise fully connected feed-forward network. <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf">Residual connections</a> and <a href="https://arxiv.org/abs/1607.06450">layer normalization</a> is used for each sub-layer.</p>
<h3 id="decoder">Decoder</h3>
<p>This also has <code>N=6</code> stacked layers. The architecture diagram shows one layer of the decoder on the right. Each layer has three sub-layers. Two of them are the same as the encoder. The third layer performs multi-head attention over the output of the encoder stack. This is modified to prevent positions from attending to subsequent positions. Additionally, the output embeddings are also offset by one position. These features ensure that the predictions for a position depend only on the known outputs for positions before it.</p>
<h3 id="attention">Attention</h3>
<p>The paper uses a modified dot product attention, and it is called &ldquo;Scaled Dot Product Attention&rdquo;. Given queries and keys of dimension d<sub>k</sub> and values of dimension d<sub>v</sub>, the attention matrix is calculated as shown below.</p>













<figure>


  <a data-fancybox="" href="/post/2021-04-18_attention_is_all_you_need/images/attention.PNG" data-caption="Attention Matrix Calculation">
<img src="/post/2021-04-18_attention_is_all_you_need/images/attention.PNG" alt="" ></a>


  
  
  <figcaption>
    Attention Matrix Calculation
  </figcaption>


</figure>

<p>Since, for large values of d<sub>k</sub> the dot product grows large in magnitude, it pushes the softmax function into regions where it has extremely small gradients. The scaling of 1/sqrt(d<sub>k</sub>) is done to avoid the problem of vanishing gradients.</p>
<p>Multi-Head attention allows computing this attention in parallel. This helps to focus on different positions. Secondly, it also helps to attend to information from different subspaces due to the more number of attention heads.</p>













<figure>


  <a data-fancybox="" href="/post/2021-04-18_attention_is_all_you_need/images/multihead-attention.PNG" data-caption="Multihead Attention Calculation">
<img src="/post/2021-04-18_attention_is_all_you_need/images/multihead-attention.PNG" alt="" ></a>


  
  
  <figcaption>
    Multihead Attention Calculation
  </figcaption>


</figure>

<p>The paper uses <code>h=8</code> parallel attention layers or heads. The reduced dimension of each head compensates for the more number of heads and hence the computational cost remains the same as with single-head attention with full dimensionality.</p>
<p>Applications of multi-head attention in the paper are given below -</p>













<figure>


  <a data-fancybox="" href="/post/2021-04-18_attention_is_all_you_need/images/application-attention.PNG" data-caption="Application of multi-head attention in the model">
<img src="/post/2021-04-18_attention_is_all_you_need/images/application-attention.PNG" alt="" ></a>


  
  
  <figcaption>
    Application of multi-head attention in the model
  </figcaption>


</figure>














<figure>


  <a data-fancybox="" href="/post/2021-04-18_attention_is_all_you_need/images/multihead-attention-fig.PNG" data-caption="Pictorial representaion of Multi-head attention">
<img src="/post/2021-04-18_attention_is_all_you_need/images/multihead-attention-fig.PNG" alt="" ></a>


  
  
  <figcaption>
    Pictorial representaion of Multi-head attention
  </figcaption>


</figure>

<h3 id="position-wise-feed-forward-networks">Position-wise Feed-Forward Networks</h3>
<p>The FFN sub-layer shown in the encoder and decoder architecture is a 2-hidden layer FC FNN with a ReLU activation in between.</p>
<h3 id="positional-encodings">Positional Encodings</h3>
<p>Positional encodings are injected (added) to the input embeddings at the bottom of the encoder and decoder stack to add some information about the relative order of the tokens in the sequence. The positional encodings have the same dimension as the input embeddings so that they can be added.
For position <em>pos</em> and dimension <em>i</em> the paper uses the following positional embeddings -</p>













<figure>


  <a data-fancybox="" href="/post/2021-04-18_attention_is_all_you_need/images/positional.PNG" data-caption="Positional Encoding calculation">
<img src="/post/2021-04-18_attention_is_all_you_need/images/positional.PNG" alt="" ></a>


  
  
  <figcaption>
    Positional Encoding calculation
  </figcaption>


</figure>

<p>This choice allows the model to easily learn by the relative positions. The learned positional embeddings also perform about the same as the sinusoidal version. The sinusoidal version may allow the model to extrapolate to sequence lengths longer than the ones encountered in training.</p>
<h2 id="results">Results</h2>













<figure>


  <a data-fancybox="" href="/post/2021-04-18_attention_is_all_you_need/images/experiments.PNG" data-caption="Experimental results when varying parameters">
<img src="/post/2021-04-18_attention_is_all_you_need/images/experiments.PNG" alt="" ></a>


  
  
  <figcaption>
    Experimental results when varying parameters
  </figcaption>


</figure>

<ul>
<li>Form (A), it can be seen that single-head attention is slightly worse than the best setting. The quality also drops off with too many heads.</li>
<li>(B) shows that reducing the attention key size <i>d<sub>k</sub></i> hurts model quality.</li>
<li>In (C) and (D), it is visible that bigger models are better and dropout helps in avoiding overfitting.</li>
<li>(E) shows that sinusoidal positional encoding when replaced with learned positional embeddings also does not lead to a loss in quality</li>
</ul>
<p>For the base models, the authors used a single model obtained by averaging the last 5 checkpoints, which were written at 10-minute intervals. The big models were averaged over the last 20 checkpoints. Beam search with a beam size of 4 and length penalty α = 0.6. The maximum output length during inference is set to input length +50, but if it is possible, the model terminates early.</p>
<p>The performance comparison with the other models is shown below -</p>













<figure>


  <a data-fancybox="" href="/post/2021-04-18_attention_is_all_you_need/images/results.PNG" data-caption="Model performance">
<img src="/post/2021-04-18_attention_is_all_you_need/images/results.PNG" alt="" ></a>


  
  
  <figcaption>
    Model performance
  </figcaption>


</figure>

<hr>
<p><strong>I have also released an annotated version of the paper. If you are interested, you can find it <a href="https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/Attention%20Is%20All%20You%20Need.pdf">here</a>.</strong></p>
<p>This is all for now!</p>
<p> </p>
<script type="text/javascript" src="//downloads.mailchimp.com/js/signup-forms/popup/unique-methods/embed.js" data-dojo-config="usePlainJson: true, isDebug: false"></script>
<!-- <button style="background-color: #70ab17; color: #1770AB" id="openpopup">Subscribe to my posts!</button> -->
<div class="button_cont" align="center"><button id="openpopup" class="example_a">Subscribe to my posts!</button></div>
<style>
    .example_a {
        color: #fff !important;
        text-transform: uppercase;
        text-decoration: none;
        background: #3f51b5;
        padding: 20px;
        border-radius: 5px;
        cursor: pointer;
        display: inline-block;
        border: none;
        transition: all 0.4s ease 0s;
    }

    .example_a:hover {
        background: #434343;
        letter-spacing: 1px;
        -webkit-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);
        -moz-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);
        box-shadow: 5px 40px -10px rgba(0,0,0,0.57);
        transition: all 0.4s ease 0s;
    }
</style>
<script type="text/javascript">

function showMailingPopUp() {
    window.dojoRequire(["mojo/signup-forms/Loader"], function(L) { L.start({"baseUrl":"mc.us4.list-manage.com","uuid":"0b10ac14f50d7f4e7d11cf26a","lid":"667a1bb3da","uniqueMethods":true}) })

    document.cookie = "MCPopupClosed=;path=/;expires=Thu, 01 Jan 1970 00:00:00 UTC";
}

document.getElementById("openpopup").onclick = function() {showMailingPopUp()};

</script>
<p> </p>
<script data-name="BMC-Widget" data-cfasync="false" src="https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js" data-id="shreyanshsingh" data-description="Support me on Buy me a coffee!" data-message="" data-color="#FF5F5F" data-position="Right" data-x_margin="18" data-y_margin="18"></script>
<p>Follow me on <a href="https://twitter.com/shreyansh_26">Twitter</a>, <a href="https://github.com/shreyansh26">Github</a> or connect on <a href="https://www.linkedin.com/in/shreyansh26/">LinkedIn</a>.</p>

    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/paper-reading/">paper reading</a>
  
  <a class="badge badge-light" href="/tags/transformers/">transformers</a>
  
  <a class="badge badge-light" href="/tags/nlp/">nlp</a>
  
  <a class="badge badge-light" href="/tags/deep-learning/">deep learning</a>
  
</div>



<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://shreyansh26.github.io/post/2021-04-18_attention_is_all_you_need/&amp;text=Paper%20Notes%20#1%20-%20Attention%20Is%20All%20You%20Need" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://shreyansh26.github.io/post/2021-04-18_attention_is_all_you_need/&amp;t=Paper%20Notes%20#1%20-%20Attention%20Is%20All%20You%20Need" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Paper%20Notes%20#1%20-%20Attention%20Is%20All%20You%20Need&amp;body=https://shreyansh26.github.io/post/2021-04-18_attention_is_all_you_need/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://shreyansh26.github.io/post/2021-04-18_attention_is_all_you_need/&amp;title=Paper%20Notes%20#1%20-%20Attention%20Is%20All%20You%20Need" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Paper%20Notes%20#1%20-%20Attention%20Is%20All%20You%20Need%20https://shreyansh26.github.io/post/2021-04-18_attention_is_all_you_need/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
  </ul>
</div>












  
  
    
  
  






  
  
  
  
  <div class="media author-card content-widget-hr">
    

    <div class="media-body">
      <h5 class="card-title"><a href="/authors/shreyansh-singh/"></a></h5>
      
      
      <ul class="network-icon" aria-hidden="true">
  
</ul>

    </div>
  </div>




<section id="comments">
  
    
<div id="disqus_thread"></div>
<script>
  let disqus_config = function () {
    
    
    
  };
  (function() {
    if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
      document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
      return;
    }
    var d = document, s = d.createElement('script'); s.async = true;
    s.src = 'https://' + "shreyansh26-netlify-com" + '.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


  
</section>




<div class="article-widget">
  
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/post/2021-04-25_deep_contextualized_word_representations_elmo/" rel="next">Paper Notes #2 - Deep contextualized word representations</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/post/2021-01-25_deep_learning_in_the_browser/" rel="prev">Deep Learning in the Browser - Exploring TF.js, WebDNN and ONNX.js</a>
  </div>
  
</div>

</div>



  
  
  <div class="article-widget content-widget-hr">
    <h3>Related</h3>
    <ul>
      
      <li><a href="/project/msr-nlg/">Multilingual Surface Realization for NLG</a></li>
      
      <li><a href="/post/2021-01-25_deep_learning_in_the_browser/">Deep Learning in the Browser - Exploring TF.js, WebDNN and ONNX.js</a></li>
      
      <li><a href="/project/privacy-ml/">Privacy-preserving Machine Learning using Secure Multiparty Computation</a></li>
      
      <li><a href="/project/revopid/">Review Opinion Diversificatio&amp;shy;n</a></li>
      
    </ul>
  </div>
  



  </div>
</article>

      

    
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js" integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/cpp.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/js.min.js"></script>
        
      

      
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    <script id="dsq-count-scr" src="https://shreyansh26-netlify-com.disqus.com/count.js" async></script>
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.bcfae8267aba63cc55af53a503896bd9.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    © Shreyansh Singh 2021 &middot; 

    Powered by 
    
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
